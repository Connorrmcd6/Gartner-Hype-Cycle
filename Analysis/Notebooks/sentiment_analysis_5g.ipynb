{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "path = '/Users/connormcdonald/Desktop/Masters/MIT807/Gartner Repository/Analysis/Figures'\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/connormcdonald/Desktop/Masters/MIT807/Gartner Repository/Data Collection')\n",
    "from configs import *\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mpl_toolkits.axisartist.axislines import SubplotZero\n",
    "from pylab import text\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"lualatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+mysqlconnector://'+user+':'+passwd+'@'+ip+':3306/'+schema1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = ''' SELECT \n",
    "DATE_FORMAT(A.date, \\'%Y-%m\\') as date, \n",
    "COUNT(1) as num_tweets,\n",
    "AVG(B.mnb_prediction) AS mnb,\n",
    "AVG(B.svm_prediction) AS svm,\n",
    "AVG(B.lr_prediction) AS lr,\n",
    "AVG(B.ensemble_prediction) AS ens\n",
    "FROM social.five_g_only A\n",
    "INNER JOIN social.fiveG_sentiment B \n",
    "ON A.id = B.id\n",
    "GROUP BY DATE_FORMAT(A.date, \\'%Y-%m\\')\n",
    "ORDER BY DATE_FORMAT(A.date, \\'%Y-%m\\') ASC'''\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "line = pd.to_datetime('2017-06-01')\n",
    "line2 = pd.to_datetime('2018-09-01')\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 5]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "ax.set_ylim([0,1])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Proportion of Positive Tweets')\n",
    "plt.plot(df.date, df.mnb, label = 'MNB')\n",
    "plt.plot(df.date, df.lr, label = 'LR')\n",
    "plt.plot(df.date, df.svm, label = 'SVM')\n",
    "plt.plot(df.date, df.ens, label = 'Ensemble')\n",
    "plt.axvline(x=line, c = '#999999', linewidth = 1, linestyle =\"--\", label = 'PoI')\n",
    "plt.axvline(x=line2, c = '#999999', linewidth = 1, linestyle =\"--\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(path, '5g_sentiment.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = ''' SELECT \n",
    "DATE_FORMAT(A.date, \\'%Y-%m\\') as date, \n",
    "AVG(B.mnb_probability) AS mnb_probability,\n",
    "AVG(B.svm_probability) AS svm_probability,\n",
    "AVG(B.lr_probability) AS lr_probability\n",
    "FROM social.five_g_only A\n",
    "INNER JOIN social.fiveG_sentiment B \n",
    "ON A.id = B.id\n",
    "GROUP BY DATE_FORMAT(A.date, \\'%Y-%m\\')\n",
    "ORDER BY DATE_FORMAT(A.date, \\'%Y-%m\\') ASC'''\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ens_probability'] = (df['mnb_probability'] + df['svm_probability'] + df['lr_probability'])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "line = pd.to_datetime('2017-06-01')\n",
    "line2 = pd.to_datetime('2018-09-01')\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4.5]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "ax.set_ylim([0,1])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Prediction Probability')\n",
    "plt.plot(df.date, df.mnb_probability, label = 'MNB Probability')\n",
    "plt.plot(df.date, df.lr_probability, label = 'LR Probability')\n",
    "plt.plot(df.date, df.svm_probability, label = 'SVM Probability')\n",
    "plt.plot(df.date, df.ens_probability, label = 'Ensemble Probability')\n",
    "plt.axvline(x=line, c = '#999999', linewidth = 1, linestyle =\"--\", label = 'PoI')\n",
    "plt.axvline(x=line2, c = '#999999', linewidth = 1, linestyle =\"--\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(path, '5g_sentiment_prob.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = '''  SELECT \n",
    "A.text\n",
    "FROM social.five_g_only A\n",
    "INNER JOIN social.fiveG_sentiment B \n",
    "ON A.id = B.id\n",
    "WHERE ensemble_prediction = 0'''\n",
    "\n",
    "negative_df = pd.read_sql(stmt, con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = '''  SELECT \n",
    "A.text\n",
    "FROM social.five_g_only A\n",
    "INNER JOIN social.fiveG_sentiment B \n",
    "ON A.id = B.id\n",
    "WHERE ensemble_prediction = 1'''\n",
    "\n",
    "positive_df = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "negative_words = Counter(\" \".join(negative_df[\"text\"]).split()).most_common(100)\n",
    "\n",
    "positive_words = Counter(\" \".join(positive_df[\"text\"]).split()).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = pd.DataFrame(negative_words, columns=['neg_word', \"neg_word_count\"])\n",
    "pos_df = pd.DataFrame(positive_words, columns=['pos_word', \"pos_word_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df= pd.merge(neg_df, pos_df, left_on='neg_word', right_on='pos_word', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('5g')\n",
    "stop_words.append('g')\n",
    "stop_words.append('5')\n",
    "\n",
    "for i in range(len(merged_df.index)):\n",
    "    if str(merged_df.neg_word[i]) in stop_words:\n",
    "        merged_df = merged_df.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_word</th>\n",
       "      <th>neg_word_count</th>\n",
       "      <th>pos_word</th>\n",
       "      <th>pos_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>la</td>\n",
       "      <td>246279</td>\n",
       "      <td>la</td>\n",
       "      <td>502122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iphone</td>\n",
       "      <td>194904</td>\n",
       "      <td>iphone</td>\n",
       "      <td>58772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de</td>\n",
       "      <td>131005</td>\n",
       "      <td>de</td>\n",
       "      <td>413531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>129638</td>\n",
       "      <td>5</td>\n",
       "      <td>74930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4g</td>\n",
       "      <td>126436</td>\n",
       "      <td>4g</td>\n",
       "      <td>144143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ipod</td>\n",
       "      <td>125247</td>\n",
       "      <td>ipod</td>\n",
       "      <td>109093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>en</td>\n",
       "      <td>113542</td>\n",
       "      <td>en</td>\n",
       "      <td>234400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>el</td>\n",
       "      <td>99422</td>\n",
       "      <td>el</td>\n",
       "      <td>187891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>que</td>\n",
       "      <td>93985</td>\n",
       "      <td>que</td>\n",
       "      <td>117010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>network</td>\n",
       "      <td>89792</td>\n",
       "      <td>network</td>\n",
       "      <td>131924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>iot</td>\n",
       "      <td>80115</td>\n",
       "      <td>iot</td>\n",
       "      <td>223744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>internet</td>\n",
       "      <td>79772</td>\n",
       "      <td>internet</td>\n",
       "      <td>98252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mobile</td>\n",
       "      <td>76638</td>\n",
       "      <td>mobile</td>\n",
       "      <td>158332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>touch</td>\n",
       "      <td>72232</td>\n",
       "      <td>touch</td>\n",
       "      <td>48135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>apple</td>\n",
       "      <td>71594</td>\n",
       "      <td>apple</td>\n",
       "      <td>67262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>case</td>\n",
       "      <td>62505</td>\n",
       "      <td>case</td>\n",
       "      <td>57397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>via</td>\n",
       "      <td>61043</td>\n",
       "      <td>via</td>\n",
       "      <td>153516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>new</td>\n",
       "      <td>59362</td>\n",
       "      <td>new</td>\n",
       "      <td>182827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>57800</td>\n",
       "      <td>1</td>\n",
       "      <td>47183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>samsung</td>\n",
       "      <td>55208</td>\n",
       "      <td>samsung</td>\n",
       "      <td>48607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>wireless</td>\n",
       "      <td>54742</td>\n",
       "      <td>wireless</td>\n",
       "      <td>106238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>con</td>\n",
       "      <td>51823</td>\n",
       "      <td>con</td>\n",
       "      <td>56221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>amp</td>\n",
       "      <td>50391</td>\n",
       "      <td>amp</td>\n",
       "      <td>146004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>technology</td>\n",
       "      <td>43311</td>\n",
       "      <td>technology</td>\n",
       "      <td>113380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>us</td>\n",
       "      <td>42498</td>\n",
       "      <td>us</td>\n",
       "      <td>68603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>huawei</td>\n",
       "      <td>41882</td>\n",
       "      <td>huawei</td>\n",
       "      <td>85345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>para</td>\n",
       "      <td>41270</td>\n",
       "      <td>para</td>\n",
       "      <td>88698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>40277</td>\n",
       "      <td>2</td>\n",
       "      <td>42020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ericsson</td>\n",
       "      <td>37684</td>\n",
       "      <td>ericsson</td>\n",
       "      <td>69193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>un</td>\n",
       "      <td>36319</td>\n",
       "      <td>un</td>\n",
       "      <td>58576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>networks</td>\n",
       "      <td>36214</td>\n",
       "      <td>networks</td>\n",
       "      <td>76527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020</td>\n",
       "      <td>35667</td>\n",
       "      <td>2020</td>\n",
       "      <td>71156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>se</td>\n",
       "      <td>35137</td>\n",
       "      <td>se</td>\n",
       "      <td>48926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nano</td>\n",
       "      <td>34943</td>\n",
       "      <td>nano</td>\n",
       "      <td>47812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tech</td>\n",
       "      <td>34551</td>\n",
       "      <td>tech</td>\n",
       "      <td>86979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>es</td>\n",
       "      <td>33978</td>\n",
       "      <td>es</td>\n",
       "      <td>57484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>e</td>\n",
       "      <td>32965</td>\n",
       "      <td>e</td>\n",
       "      <td>45892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>first</td>\n",
       "      <td>30323</td>\n",
       "      <td>first</td>\n",
       "      <td>97915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>di</td>\n",
       "      <td>28540</td>\n",
       "      <td>di</td>\n",
       "      <td>53214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>te</td>\n",
       "      <td>28094</td>\n",
       "      <td>te</td>\n",
       "      <td>77285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      neg_word  neg_word_count    pos_word  pos_word_count\n",
       "0           la          246279          la          502122\n",
       "1       iphone          194904      iphone           58772\n",
       "2           de          131005          de          413531\n",
       "3            5          129638           5           74930\n",
       "4           4g          126436          4g          144143\n",
       "5         ipod          125247        ipod          109093\n",
       "6           en          113542          en          234400\n",
       "7           el           99422          el          187891\n",
       "8          que           93985         que          117010\n",
       "9      network           89792     network          131924\n",
       "10         iot           80115         iot          223744\n",
       "11    internet           79772    internet           98252\n",
       "12      mobile           76638      mobile          158332\n",
       "13       touch           72232       touch           48135\n",
       "14       apple           71594       apple           67262\n",
       "15        case           62505        case           57397\n",
       "16         via           61043         via          153516\n",
       "17         new           59362         new          182827\n",
       "18           1           57800           1           47183\n",
       "19     samsung           55208     samsung           48607\n",
       "20    wireless           54742    wireless          106238\n",
       "21         con           51823         con           56221\n",
       "22         amp           50391         amp          146004\n",
       "23  technology           43311  technology          113380\n",
       "24          us           42498          us           68603\n",
       "25      huawei           41882      huawei           85345\n",
       "26        para           41270        para           88698\n",
       "27           2           40277           2           42020\n",
       "28    ericsson           37684    ericsson           69193\n",
       "29          un           36319          un           58576\n",
       "30    networks           36214    networks           76527\n",
       "31        2020           35667        2020           71156\n",
       "32          se           35137          se           48926\n",
       "33        nano           34943        nano           47812\n",
       "34        tech           34551        tech           86979\n",
       "35          es           33978          es           57484\n",
       "36           e           32965           e           45892\n",
       "37       first           30323       first           97915\n",
       "38          di           28540          di           53214\n",
       "39          te           28094          te           77285"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "merged_df[['neg_word_count_norm', 'pos_word_count_norm']] = scaler.fit_transform(merged_df[['neg_word_count', 'pos_word_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmerged_pos = merged_df.iloc[:, [2,3, 5]].sort_values(by=['pos_word_count'], ascending=False)\n",
    "unmerged_neg = merged_df.iloc[:, [0,1, 4]].sort_values(by=['neg_word_count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_pos = unmerged_pos.head(10).pos_word.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_neg = unmerged_neg.head(10).neg_word.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = list(top_10_pos)\n",
    "top_words.extend(x for x in top_10_neg if x not in top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for i in range(len(merged_df.index)):\n",
    "    if merged_df.neg_word.values[i] in top_words:\n",
    "        f.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = merged_df.iloc[f,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.grid(linestyle='--', linewidth=0.5)\n",
    "ax = sns.scatterplot(x='neg_word_count_norm',y='pos_word_count_norm',hue = 'neg_word',data = final_df,legend='full',s=50)\n",
    "ax.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.xlabel('Normalised Count in Negative Tweets')\n",
    "plt.ylabel('Normalised Count in Positive Tweets')\n",
    "plt.savefig(os.path.join(path, '5G_word_occurrence.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f339fb3a027be473131e6ac829b8dc34fc7d4e2b227bdb2c2c5f9829538e0fed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
