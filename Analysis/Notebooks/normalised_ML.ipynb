{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "path = '/Users/connormcdonald/Desktop/Masters/MIT807/Gartner Repository/Analysis/Figures'\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/connormcdonald/Desktop/Masters/MIT807/Gartner Repository/Data Collection')\n",
    "from configs import *\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mpl_toolkits.axisartist.axislines import SubplotZero\n",
    "from pylab import text\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"lualatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+mysqlconnector://'+user+':'+passwd+'@'+ip+':3306/'+schema1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/connormcdonald/Desktop/Masters/MIT807/Data/twitterMAU.csv')\n",
    "df['period']  = pd.to_datetime(df['period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.iloc[:38,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "degree = 3\n",
    "y = np.array(df1['mau'].to_list())\n",
    "X = np.array(mdates.date2num(df1['period']))\n",
    "date_index = []\n",
    "idx = 0\n",
    "for i in X:\n",
    "    date_index.append(idx)\n",
    "    idx += 1\n",
    "\n",
    "z = np.polyfit(date_index, y, degree)\n",
    "f = np.poly1d(z)\n",
    "\n",
    "df_trend = pd.DataFrame(columns=['X', 'y','d'])\n",
    "df_trend['X'] = date_index\n",
    "df_trend['y'] = y\n",
    "df_trend['d'] = X\n",
    "\n",
    "\n",
    "z = np.polyfit(df_trend.d, df_trend.y, degree)\n",
    "model = np.poly1d(z)\n",
    "results = smf.ols(formula='y ~ model(X)', data=df_trend).fit()\n",
    "\n",
    "# print(results.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mdates.date2num(df['period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fit = mdates.date2num(df['period'])\n",
    "y_fit = [model(_x) for _x in x_fit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dformat(d):\n",
    "    return d.strftime('%Y-%m')\n",
    "\n",
    "def yformat(d):\n",
    "    return d.strftime('%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_fit'] = y_fit\n",
    "df['combined_mau'] = np.where(df[\"mau\"].isnull(), df[\"y_fit\"], df[\"mau\"] )*1000000\n",
    "df['period_formatted'] = df['period'].apply(dformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = '''SELECT DATE_FORMAT(date, \\'%Y-%m\\') as date, \n",
    "COUNT(1) AS tweets,\n",
    "SUM(like_count) as likes,\n",
    "SUM(quote_count) as quotes,\n",
    "SUM(reply_count) as comments,\n",
    "SUM(retweet_count) as retweets\n",
    "FROM social.machine_learning_only \n",
    "group by DATE_FORMAT(date, \\'%Y-%m\\') \n",
    "ORDER BY DATE_FORMAT(date, \\'%Y-%m\\') ASC'''\n",
    "df2 = pd.read_sql(stmt, con=engine)\n",
    "\n",
    "df3 = pd.merge(df, df2, left_on='period_formatted', right_on='date', how='inner')\n",
    "\n",
    "df3['tweets_p_user'] = df3['tweets']/df3['combined_mau']\n",
    "\n",
    "df3['likes_p_user'] = df3['likes']/df3['combined_mau']\n",
    "df3['comments_p_user'] = df3['comments']/df3['combined_mau']\n",
    "df3['quotes_p_user'] = df3['quotes']/df3['combined_mau']\n",
    "df3['retweets_p_user'] = df3['retweets']/df3['combined_mau']\n",
    "\n",
    "df3['total_engagement'] = df3['likes_p_user'] + df3['comments_p_user'] + df3['quotes_p_user'] + df3['retweets_p_user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 0.6553834907465326\n",
      "pre: 0.9354011567434544\n",
      "post: 0.3025691093319154\n"
     ]
    }
   ],
   "source": [
    "correlation_df = df3\n",
    "correlation_df['date']  = pd.to_datetime(correlation_df['date'])\n",
    "\n",
    "correlation_pre = correlation_df[correlation_df.period_formatted < '2020-03-01']\n",
    "correlation_post = correlation_df[correlation_df.period_formatted >= '2020-03-01']\n",
    "\n",
    "\n",
    "column_1 = correlation_df[\"tweets_p_user\"]\n",
    "column_2 = correlation_df[\"total_engagement\"]\n",
    "correlation = column_1.corr(column_2)\n",
    "print(f\"total: {correlation}\")\n",
    "\n",
    "\n",
    "column_1 = correlation_pre[\"tweets_p_user\"]\n",
    "column_2 = correlation_pre[\"total_engagement\"]\n",
    "correlation = column_1.corr(column_2)\n",
    "print(f\"pre: {correlation}\")\n",
    "\n",
    "\n",
    "column_1 = correlation_post[\"tweets_p_user\"]\n",
    "column_2 = correlation_post[\"total_engagement\"]\n",
    "correlation = column_1.corr(column_2)\n",
    "print(f\"post: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c7/dcyx4ss130ldp4lp9ph0v16c0000gn/T/ipykernel_83055/2356826354.py:1: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "corr = []\n",
    "c = []\n",
    "p = []\n",
    "for i in range(2, len(correlation_df.index)):\n",
    "    temp_df = correlation_df.iloc[:i,:]\n",
    "    tweets = temp_df.tweets_p_user\n",
    "    engagement = temp_df.total_engagement\n",
    "    correlation = tweets.corr(engagement)\n",
    "    corr.append(correlation)\n",
    "    x = pearsonr(engagement, tweets)\n",
    "    c.append(x[0])\n",
    "    p.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr plot\n",
    "line = pd.to_datetime('2013-06-01')\n",
    "line2 = pd.to_datetime('2020-03-01')\n",
    "line3 = pd.to_datetime('2017-12-01')\n",
    "line4 = pd.to_datetime('2014-06-01')\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Correlation')\n",
    "plt.plot(correlation_df.loc[2:].date, corr, c = 'black', linewidth = 1)\n",
    "plt.plot(correlation_df.loc[2:].date, p, c = 'green', linewidth = 1)\n",
    "plt.axvline(x=line, c = '#E31B23', linewidth = 1, linestyle =\"--\", label= 'POI-A')\n",
    "plt.axvline(x=line4, c = '#339898', linewidth = 1, linestyle =\"--\", label = \"POI-B\")\n",
    "plt.axvline(x=line3, c = '#999999', linewidth = 1, linestyle =\"--\", label= 'POI-C')\n",
    "plt.axvline(x=line2, c = '#FF9A00', linewidth = 1, linestyle =\"--\", label= 'POI-D')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(os.path.join(path, 'ml_correleation.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 3\n",
    "y = np.array(df3['tweets_p_user'].to_list())\n",
    "X = np.array(mdates.date2num(df3['date']))\n",
    "date_index = []\n",
    "idx = 0\n",
    "for i in X:\n",
    "    date_index.append(idx)\n",
    "    idx += 1\n",
    "\n",
    "z = np.polyfit(date_index, y, degree)\n",
    "f = np.poly1d(z)\n",
    "\n",
    "df_trend = pd.DataFrame(columns=['X', 'y','d'])\n",
    "df_trend['X'] = date_index\n",
    "df_trend['y'] = y\n",
    "df_trend['d'] = X\n",
    "\n",
    "\n",
    "z = np.polyfit(df_trend.d, df_trend.y, degree)\n",
    "model = np.poly1d(z)\n",
    "results = smf.ols(formula='y ~ model(X)', data=df_trend).fit()\n",
    "\n",
    "\n",
    "X = mdates.date2num(df3['date'])\n",
    "\n",
    "x_fit = mdates.date2num(df3['date'])\n",
    "y_fit = [model(_x) for _x in x_fit]\n",
    "\n",
    "df3['y_fit_2'] = y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(results.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>mau</th>\n",
       "      <th>y_fit</th>\n",
       "      <th>combined_mau</th>\n",
       "      <th>period_formatted</th>\n",
       "      <th>date</th>\n",
       "      <th>tweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>quotes</th>\n",
       "      <th>comments</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweets_p_user</th>\n",
       "      <th>likes_p_user</th>\n",
       "      <th>comments_p_user</th>\n",
       "      <th>quotes_p_user</th>\n",
       "      <th>retweets_p_user</th>\n",
       "      <th>total_engagement</th>\n",
       "      <th>y_fit_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.282818</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>2010-03</td>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>765</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.106319</td>\n",
       "      <td>40000000.0</td>\n",
       "      <td>2010-06</td>\n",
       "      <td>2010-06-01</td>\n",
       "      <td>701</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-09-30</td>\n",
       "      <td>49.0</td>\n",
       "      <td>44.504028</td>\n",
       "      <td>49000000.0</td>\n",
       "      <td>2010-09</td>\n",
       "      <td>2010-09-01</td>\n",
       "      <td>746</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.040816e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>54.0</td>\n",
       "      <td>63.256920</td>\n",
       "      <td>54000000.0</td>\n",
       "      <td>2010-12</td>\n",
       "      <td>2010-12-01</td>\n",
       "      <td>744</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.980447</td>\n",
       "      <td>68000000.0</td>\n",
       "      <td>2011-03</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>2182</td>\n",
       "      <td>412.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.470588e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      period   mau      y_fit  combined_mau period_formatted       date  \\\n",
       "0 2010-03-31  30.0   5.282818    30000000.0          2010-03 2010-03-01   \n",
       "1 2010-06-30  40.0  25.106319    40000000.0          2010-06 2010-06-01   \n",
       "2 2010-09-30  49.0  44.504028    49000000.0          2010-09 2010-09-01   \n",
       "3 2010-12-31  54.0  63.256920    54000000.0          2010-12 2010-12-01   \n",
       "4 2011-03-31  68.0  80.980447    68000000.0          2011-03 2011-03-01   \n",
       "\n",
       "   tweets  likes  quotes  comments  retweets  tweets_p_user  likes_p_user  \\\n",
       "0     765   98.0     0.0       0.0      76.0       0.000025      0.000003   \n",
       "1     701  105.0     0.0       1.0      62.0       0.000018      0.000003   \n",
       "2     746  240.0     0.0       1.0     168.0       0.000015      0.000005   \n",
       "3     744  151.0     0.0       0.0     133.0       0.000014      0.000003   \n",
       "4    2182  412.0     0.0       1.0     339.0       0.000032      0.000006   \n",
       "\n",
       "   comments_p_user  quotes_p_user  retweets_p_user  total_engagement   y_fit_2  \n",
       "0     0.000000e+00            0.0         0.000003          0.000006  0.000047  \n",
       "1     2.500000e-08            0.0         0.000002          0.000004  0.000035  \n",
       "2     2.040816e-08            0.0         0.000003          0.000008  0.000025  \n",
       "3     0.000000e+00            0.0         0.000002          0.000005  0.000017  \n",
       "4     1.470588e-08            0.0         0.000005          0.000011  0.000010  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-06\n",
      "2017-12\n"
     ]
    }
   ],
   "source": [
    "curr_max_freq = 0\n",
    "curr_max_eng = 0\n",
    "for i in range(len(df3.index)-1):\n",
    "    a = df3.tweets_p_user[i]\n",
    "    b = df3.tweets_p_user[i+1]\n",
    "\n",
    "    c = df3.total_engagement[i]\n",
    "    d = df3.total_engagement[i+1]\n",
    "\n",
    "\n",
    "    if a > b and i !=0 and c > d and a > curr_max_freq and c > curr_max_eng and c > a:\n",
    "        print(df3.period_formatted[i])\n",
    "        curr_max_freq = df3.tweets_p_user[i]\n",
    "        curr_max_eng = df3.total_engagement[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML plot\n",
    "df3['date']  = pd.to_datetime(df3['date'])\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [6,6]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Monthly Tweets Per Active User')\n",
    "plt.plot(df3['date'], df3['tweets_p_user'], c = '#339898', linewidth = 1, label = 'Tweets')\n",
    "plt.plot(df3['date'], df3['y_fit_2'], c = '#E31B23', linewidth = 1, linestyle =\"--\", label= 'Polynomial Trend Line\\n ($R^2$ = 0.686)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(os.path.join(path, 'ml_normalised_tweets.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [6,6]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "\n",
    "#define colors to use in chart\n",
    "color_map = ['#339898', '#E31B23', '#999999', '#FF9A00']\n",
    "\n",
    "#create area chart\n",
    "plt.stackplot(df3['date'], df3['likes_p_user'], df3['comments_p_user'], df3['quotes_p_user'],df3['retweets_p_user'],\n",
    "              labels=['Likes', 'Comments', 'Quotes', 'Retweets'],\n",
    "              colors=color_map,\n",
    "              alpha=0.6)\n",
    "plt.plot(df3['date'], df3['tweets_p_user'], c = 'black', linewidth = 1,label = 'Tweets')\n",
    "\n",
    "#add legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "#add axis labels\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Monthly Metrics Per Active User')\n",
    "plt.savefig(os.path.join(path, 'ml_normalised_area.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML plot\n",
    "line = pd.to_datetime('2013-06-01')\n",
    "line2 = pd.to_datetime('2020-03-01')\n",
    "line3 = pd.to_datetime('2017-12-01')\n",
    "line4 = pd.to_datetime('2014-06-01')\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [6,6]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Monthly Tweets Per Active User')\n",
    "plt.plot(df3['date'], df3['tweets_p_user'], c = 'black', linewidth = 1, label = 'Tweets')\n",
    "plt.axvline(x=line, c = '#E31B23', linewidth = 1, linestyle =\"--\", label= 'POI-A')\n",
    "plt.axvline(x=line4, c = '#339898', linewidth = 1, linestyle =\"--\", label = \"POI-Bi\")\n",
    "plt.axvline(x=line3, c = '#999999', linewidth = 1, linestyle =\"--\", label= 'POI-Bii')\n",
    "plt.axvline(x=line2, c = '#FF9A00', linewidth = 1, linestyle =\"--\", label= 'POI-D')\n",
    "\n",
    "# plt.plot(df3['date'], df3['y_fit_2'], c = '#E31B23', linewidth = 1, linestyle =\"--\", label= 'Polynomial Trend Line (R^2 = 0.686)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(os.path.join(path, 'ml_shift.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/connormcdonald/Desktop/Masters/MIT807/Data/academic_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = ['2010-12-31', '2011-12-31', '2012-12-31', '2013-12-31', '2014-12-31', '2015-12-31', '2016-12-31', '2017-12-31', '2018-12-31', '2019-12-31', '2020-12-31', '2021-12-31']\n",
    "papers = [6572, 7207, 7937, 9308, 11141, 13609, 17449, 23410, 35663, 59378, 70504, 90290]\n",
    "df['papers'] = papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scopus_norm'] = df['papers']/df['scopus_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>scholar_results</th>\n",
       "      <th>scopus_results</th>\n",
       "      <th>papers</th>\n",
       "      <th>scopus_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>4510000</td>\n",
       "      <td>2478126</td>\n",
       "      <td>6572</td>\n",
       "      <td>0.002652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>4590000</td>\n",
       "      <td>2638921</td>\n",
       "      <td>7207</td>\n",
       "      <td>0.002731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>4670000</td>\n",
       "      <td>2775816</td>\n",
       "      <td>7937</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>4360000</td>\n",
       "      <td>2901649</td>\n",
       "      <td>9308</td>\n",
       "      <td>0.003208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>4640000</td>\n",
       "      <td>2942515</td>\n",
       "      <td>11141</td>\n",
       "      <td>0.003786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>4710000</td>\n",
       "      <td>2953613</td>\n",
       "      <td>13609</td>\n",
       "      <td>0.004608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>3040000</td>\n",
       "      <td>3055033</td>\n",
       "      <td>17449</td>\n",
       "      <td>0.005712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>3450000</td>\n",
       "      <td>3151892</td>\n",
       "      <td>23410</td>\n",
       "      <td>0.007427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>3960000</td>\n",
       "      <td>3283566</td>\n",
       "      <td>35663</td>\n",
       "      <td>0.010861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>3500000</td>\n",
       "      <td>3437602</td>\n",
       "      <td>59378</td>\n",
       "      <td>0.017273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020</td>\n",
       "      <td>4000000</td>\n",
       "      <td>3576254</td>\n",
       "      <td>70504</td>\n",
       "      <td>0.019714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021</td>\n",
       "      <td>6050000</td>\n",
       "      <td>3869484</td>\n",
       "      <td>90290</td>\n",
       "      <td>0.023334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    period  scholar_results  scopus_results  papers  scopus_norm\n",
       "0     2010          4510000         2478126    6572     0.002652\n",
       "1     2011          4590000         2638921    7207     0.002731\n",
       "2     2012          4670000         2775816    7937     0.002859\n",
       "3     2013          4360000         2901649    9308     0.003208\n",
       "4     2014          4640000         2942515   11141     0.003786\n",
       "5     2015          4710000         2953613   13609     0.004608\n",
       "6     2016          3040000         3055033   17449     0.005712\n",
       "7     2017          3450000         3151892   23410     0.007427\n",
       "8     2018          3960000         3283566   35663     0.010861\n",
       "9     2019          3500000         3437602   59378     0.017273\n",
       "10    2020          4000000         3576254   70504     0.019714\n",
       "11    2021          6050000         3869484   90290     0.023334"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "degree = 3\n",
    "y = np.array(df['scopus_norm'].to_list())\n",
    "X = np.array(mdates.date2num(df['period']))\n",
    "date_index = []\n",
    "idx = 0\n",
    "for i in X:\n",
    "    date_index.append(idx)\n",
    "    idx += 1\n",
    "\n",
    "z = np.polyfit(date_index, y, degree)\n",
    "f = np.poly1d(z)\n",
    "\n",
    "df_trend = pd.DataFrame(columns=['X', 'y','d'])\n",
    "df_trend['X'] = date_index\n",
    "df_trend['y'] = y\n",
    "df_trend['d'] = X\n",
    "\n",
    "\n",
    "z = np.polyfit(df_trend.d, df_trend.y, degree)\n",
    "model = np.poly1d(z)\n",
    "results = smf.ols(formula='y ~ model(X)', data=df_trend).fit()\n",
    "\n",
    "\n",
    "X = mdates.date2num(df['period'])\n",
    "\n",
    "x_fit = mdates.date2num(df['period'])\n",
    "y_fit = [model(_x) for _x in x_fit]\n",
    "\n",
    "df['y_fit_2'] = y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(results.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML plot\n",
    "# df['period']  = pd.to_datetime(df['period'])\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [6,6]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Proportion of Machine Learning Publications')\n",
    "plt.plot(df['period'], df['scopus_norm'], c = '#339898', linewidth = 1, label ='Publications')\n",
    "plt.plot(df['period'], df['y_fit_2'], c = '#E31B23', linewidth = 1, linestyle =\"--\", label= 'Polynomial Trend Line ($R^2$ = 0.901)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(os.path.join(path, 'ml_normalised_pubs.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = 'SELECT CHAR_LENGTH (text) as char_count, YEAR(date) as year FROM social.machine_learning_only'\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  year\n",
       "0          85  2010\n",
       "1          64  2010\n",
       "2         109  2010\n",
       "3          50  2010\n",
       "4          57  2010"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax = sns.violinplot(x=\"year\", y=\"char_count\", data=df, linewidth=1)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Character Count Per Tweet')\n",
    "plt.savefig(os.path.join(path, 'char_count.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Innovation Trigger\n",
    "\n",
    "stmt = '''\n",
    "SELECT A.text, B.*\n",
    "FROM social.machine_learning_only A\n",
    "INNER JOIN ML_sentiment B\n",
    "ON A.id = B.id\n",
    "WHERE A.date >= \\'2013-05-01\\' and A.date <= \\'2013-06-30\\'\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining dictionary containing all emojis with their meanings.\n",
    "emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad', \n",
    "          ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n",
    "          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\\\': 'annoyed', \n",
    "          ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
    "          '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n",
    "          '<(-_-)>': 'robot', 'd[-_-]b': 'dj', \":'-)\": 'sadsmile', ';)': 'wink', \n",
    "          ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}\n",
    "          \n",
    "## Defining set containing all stopwords in english.\n",
    "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
    "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from', \n",
    "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're',\n",
    "             's', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
    "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those', \n",
    "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
    "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "             'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
    "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "\n",
    "# nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "def preprocess(textdata):\n",
    "    processedText = []\n",
    "    \n",
    "    # Create Lemmatizer and Stemmer.\n",
    "    wordLemm = WordNetLemmatizer()\n",
    "    \n",
    "    # Defining regex patterns.\n",
    "    urlPattern        = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "    userPattern       = '@[^\\s]+'\n",
    "    alphaPattern      = \"[^a-zA-Z0-9]\"\n",
    "    sequencePattern   = r\"(.)\\1\\1+\"\n",
    "    seqReplacePattern = r\"\\1\\1\"\n",
    "    \n",
    "    for tweet in textdata:\n",
    "        tweet = tweet.lower()\n",
    "        \n",
    "        # Replace all URls with 'URL'\n",
    "        tweet = re.sub(urlPattern,' URL',tweet)\n",
    "        # Replace all emojis.\n",
    "        for emoji in emojis.keys():\n",
    "            tweet = tweet.replace(emoji, \"EMOJI\" + emojis[emoji])        \n",
    "        # Replace @USERNAME to 'USER'.\n",
    "        tweet = re.sub(userPattern,' USER', tweet)        \n",
    "        # Replace all non alphabets.\n",
    "        tweet = re.sub(alphaPattern, \" \", tweet)\n",
    "        # Replace 3 or more consecutive letters by 2 letter.\n",
    "        tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
    "\n",
    "        tweetwords = ''\n",
    "        for word in tweet.split():\n",
    "            # Checking if the word is a stopword.\n",
    "            #if word not in stopwordlist:\n",
    "            if len(word)>1:\n",
    "                # Lemmatizing the word.\n",
    "                word = wordLemm.lemmatize(word)\n",
    "                tweetwords += (word+' ')\n",
    "            \n",
    "        processedText.append(tweetwords)\n",
    "        \n",
    "    return processedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing complete.\n",
      "Time Taken: 1 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text = df['text']\n",
    "t = time.time()\n",
    "processedtext = preprocess(text)\n",
    "print(f'Text Preprocessing complete.')\n",
    "print(f'Time Taken: {round(time.time()-t)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Total Wordcloud\n",
    "allwords = ' '.join([tweets for tweets in processedtext]) \n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('machine')\n",
    "stop_words.append('learning')\n",
    "stop_words.append('machinelearning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 300\n",
    "# plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "wordCloud = WordCloud(\n",
    "    font_path='/Library/Fonts/cmunrm.ttf',\n",
    "    width=800, \n",
    "    height=800,\n",
    "    background_color=\"white\",\n",
    "    max_font_size = 200,\n",
    "    min_font_size = 15,\n",
    "    collocation_threshold = 50,\n",
    "    stopwords=stop_words,\n",
    "    random_state=1,\n",
    "    colormap=\"gist_heat\").generate(allwords)\n",
    "plt.imshow(wordCloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(path, 'ml_innovation_trigger.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first peak\n",
    "\n",
    "stmt = '''\n",
    "SELECT A.text, B.*\n",
    "FROM social.machine_learning_only A\n",
    "INNER JOIN ML_sentiment B\n",
    "ON A.id = B.id\n",
    "WHERE A.date >= \\'2014-05-01\\' and A.date <= \\'2014-06-30\\'\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing complete.\n",
      "Time Taken: 1 seconds\n"
     ]
    }
   ],
   "source": [
    "text = df['text']\n",
    "t = time.time()\n",
    "processedtext = preprocess(text)\n",
    "print(f'Text Preprocessing complete.')\n",
    "print(f'Time Taken: {round(time.time()-t)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords = ' '.join([tweets for tweets in processedtext])\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "wordCloud = WordCloud(\n",
    "    font_path='/Library/Fonts/cmunrm.ttf',\n",
    "    width=800, \n",
    "    height=800,\n",
    "    background_color=\"white\",\n",
    "    max_font_size = 200,\n",
    "    min_font_size = 15,\n",
    "    collocation_threshold = 50,\n",
    "    stopwords=stop_words,\n",
    "    random_state=1,\n",
    "    colormap=\"gist_heat\").generate(allwords)\n",
    "plt.imshow(wordCloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(path, 'ml_peak_1.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second peak\n",
    "\n",
    "stmt = '''\n",
    "SELECT A.text, B.*\n",
    "FROM social.machine_learning_only A\n",
    "INNER JOIN ML_sentiment B\n",
    "ON A.id = B.id\n",
    "WHERE A.date >= \\'2017-11-01\\' and A.date <= \\'2017-12-31\\'\n",
    "'''\n",
    "\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing complete.\n",
      "Time Taken: 10 seconds\n"
     ]
    }
   ],
   "source": [
    "text = df['text']\n",
    "t = time.time()\n",
    "processedtext = preprocess(text)\n",
    "print(f'Text Preprocessing complete.')\n",
    "print(f'Time Taken: {round(time.time()-t)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords = ' '.join([tweets for tweets in processedtext])\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "wordCloud = WordCloud(\n",
    "    font_path='/Library/Fonts/cmunrm.ttf',\n",
    "    width=800, \n",
    "    height=800,\n",
    "    background_color=\"white\",\n",
    "    max_font_size = 200,\n",
    "    min_font_size = 20,\n",
    "    collocation_threshold = 50,\n",
    "    stopwords=stop_words,\n",
    "    random_state=1,\n",
    "    colormap=\"gist_heat\").generate(allwords)\n",
    "plt.imshow(wordCloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(path, 'ml_peak_2.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trough\n",
    "\n",
    "stmt = '''\n",
    "SELECT A.text, B.*\n",
    "FROM social.machine_learning_only A\n",
    "INNER JOIN ML_sentiment B\n",
    "ON A.id = B.id\n",
    "WHERE A.date >= \\'2020-02-01\\' and A.date <= \\'2020-03-31\\'\n",
    "'''\n",
    "\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing complete.\n",
      "Time Taken: 7 seconds\n"
     ]
    }
   ],
   "source": [
    "text = df['text']\n",
    "t = time.time()\n",
    "processedtext = preprocess(text)\n",
    "print(f'Text Preprocessing complete.')\n",
    "print(f'Time Taken: {round(time.time()-t)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords = ' '.join([tweets for tweets in processedtext])\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "wordCloud = WordCloud(\n",
    "    font_path='/Library/Fonts/cmunrm.ttf',\n",
    "    width=800, \n",
    "    height=800,\n",
    "    background_color=\"white\",\n",
    "    max_font_size = 200,\n",
    "    min_font_size = 20,\n",
    "    collocation_threshold = 50,\n",
    "    stopwords=stop_words,\n",
    "    random_state=1,\n",
    "    colormap=\"gist_heat\").generate(allwords)\n",
    "plt.imshow(wordCloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(path, 'ml_trough.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f339fb3a027be473131e6ac829b8dc34fc7d4e2b227bdb2c2c5f9829538e0fed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
