{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "path = '/Users/connormcdonald/Desktop/Masters/MIT807/Gartner Repository/Analysis/Figures'\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/connormcdonald/Desktop/Masters/MIT807/Gartner Repository/Data Collection')\n",
    "from configs import *\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mpl_toolkits.axisartist.axislines import SubplotZero\n",
    "from pylab import text\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"lualatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+mysqlconnector://'+user+':'+passwd+'@'+ip+':3306/'+schema1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = ''' SELECT \n",
    "DATE_FORMAT(A.date, \\'%Y-%m\\') as date, \n",
    "COUNT(1) as num_tweets,\n",
    "AVG(B.mnb_prediction) AS mnb,\n",
    "AVG(B.svm_prediction) AS svm,\n",
    "AVG(B.lr_prediction) AS lr,\n",
    "AVG(B.ensemble_prediction) AS ens\n",
    "FROM social.machine_learning_only A\n",
    "INNER JOIN social.ML_sentiment B \n",
    "ON A.id = B.id\n",
    "GROUP BY DATE_FORMAT(A.date, \\'%Y-%m\\')\n",
    "ORDER BY DATE_FORMAT(A.date, \\'%Y-%m\\') ASC'''\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "line = pd.to_datetime('2013-06-01')\n",
    "line2 = pd.to_datetime('2014-06-01')\n",
    "line3 = pd.to_datetime('2017-12-01')\n",
    "line4 = pd.to_datetime('2020-03-01')\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "ax.set_ylim([0,1])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Proportion of Positive Tweets')\n",
    "plt.plot(df.date, df.mnb, label = 'MNB')\n",
    "plt.plot(df.date, df.lr, label = 'LR')\n",
    "plt.plot(df.date, df.svm, label = 'SVM')\n",
    "plt.plot(df.date, df.ens, label = 'Ensemble')\n",
    "plt.axvline(x=line, c = '#999999', linewidth = 1, linestyle =\"--\", label = 'PoI')\n",
    "plt.axvline(x=line2, c = '#999999', linewidth = 1, linestyle =\"--\")\n",
    "plt.axvline(x=line3, c = '#999999', linewidth = 1, linestyle =\"--\")\n",
    "plt.axvline(x=line4, c = '#999999', linewidth = 1, linestyle =\"--\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(path, 'ml_sentiment.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = '''SELECT \n",
    "DATE_FORMAT(C.date, \\'%Y-%m\\') as date, \n",
    "AVG(C.mnb_prob) AS mnb_probability,\n",
    "AVG(C.svm_prob) AS svm_probability,\n",
    "AVG(C.lr_prob) AS lr_probability\n",
    "FROM\n",
    "(SELECT A.date,\n",
    "CASE WHEN B.mnb_prediction = 0 THEN (1 - B.mnb_probability) ELSE B.mnb_probability END as mnb_prob,\n",
    "CASE WHEN B.lr_prediction = 0 THEN (1 - B.lr_probability) ELSE B.lr_probability END as lr_prob,\n",
    "CASE WHEN B.svm_prediction = 0 THEN (1 - B.svm_probability) ELSE B.svm_probability END as svm_prob\n",
    "FROM machine_learning_only A \n",
    "INNER JOIN ML_sentiment B\n",
    "ON A.id = B.id) C\n",
    "GROUP BY DATE_FORMAT(C.date, \\'%Y-%m\\')\n",
    "ORDER BY DATE_FORMAT(C.date, \\'%Y-%m\\') ASC'''\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ens_probability'] = (df['mnb_probability'] + df['svm_probability'] + df['lr_probability'])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "line = pd.to_datetime('2013-06-01')\n",
    "line2 = pd.to_datetime('2014-06-01')\n",
    "line3 = pd.to_datetime('2017-12-01')\n",
    "line4 = pd.to_datetime('2020-03-01')\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "ax.set_ylim([0,1])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Prediction Probability')\n",
    "plt.plot(df.date, df.mnb_probability, label = 'MNB Probability')\n",
    "plt.plot(df.date, df.lr_probability, label = 'LR Probability')\n",
    "plt.plot(df.date, df.svm_probability, label = 'SVM Probability')\n",
    "plt.plot(df.date, df.ens_probability, label = 'Ensemble Probability')\n",
    "plt.axvline(x=line, c = '#999999', linewidth = 1, linestyle =\"--\", label = 'PoI')\n",
    "plt.axvline(x=line2, c = '#999999', linewidth = 1, linestyle =\"--\")\n",
    "plt.axvline(x=line3, c = '#999999', linewidth = 1, linestyle =\"--\")\n",
    "plt.axvline(x=line4, c = '#999999', linewidth = 1, linestyle =\"--\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(path, 'ml_sentiment_prob.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = '''  SELECT \n",
    "A.text\n",
    "FROM social.machine_learning_only A\n",
    "INNER JOIN social.ML_sentiment B \n",
    "ON A.id = B.id\n",
    "WHERE ensemble_prediction = 0'''\n",
    "\n",
    "negative_df = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = '''  SELECT \n",
    "A.text\n",
    "FROM social.machine_learning_only A\n",
    "INNER JOIN social.ML_sentiment B \n",
    "ON A.id = B.id\n",
    "WHERE ensemble_prediction = 1'''\n",
    "\n",
    "positive_df = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-36e8ec66b436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnegative_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegative_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpositive_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    550\u001b[0m         '''\n\u001b[1;32m    551\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    635\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fast path when counter is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "negative_words = Counter(\" \".join(negative_df[\"text\"]).split()).most_common(1000)\n",
    "\n",
    "positive_words = Counter(\" \".join(positive_df[\"text\"]).split()).most_common(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = pd.DataFrame(negative_words, columns=['neg_word', \"neg_word_count\"])\n",
    "pos_df = pd.DataFrame(positive_words, columns=['pos_word', \"pos_word_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df= pd.merge(neg_df, pos_df, left_on='neg_word', right_on='pos_word', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('learning')\n",
    "stop_words.append('machine')\n",
    "\n",
    "for i in range(len(merged_df.index)):\n",
    "    if str(merged_df.neg_word[i]) in stop_words:\n",
    "        merged_df = merged_df.drop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_word</th>\n",
       "      <th>neg_word_count</th>\n",
       "      <th>pos_word</th>\n",
       "      <th>pos_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>218601</td>\n",
       "      <td>data</td>\n",
       "      <td>566608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>science</td>\n",
       "      <td>94229</td>\n",
       "      <td>science</td>\n",
       "      <td>177311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machinelearning</td>\n",
       "      <td>93401</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>598956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ai</td>\n",
       "      <td>92834</td>\n",
       "      <td>ai</td>\n",
       "      <td>939058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml</td>\n",
       "      <td>35018</td>\n",
       "      <td>ml</td>\n",
       "      <td>266853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>unsupervised</td>\n",
       "      <td>1064</td>\n",
       "      <td>unsupervised</td>\n",
       "      <td>14603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>across</td>\n",
       "      <td>1054</td>\n",
       "      <td>across</td>\n",
       "      <td>15198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>opportunity</td>\n",
       "      <td>1053</td>\n",
       "      <td>opportunity</td>\n",
       "      <td>13106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>give</td>\n",
       "      <td>1052</td>\n",
       "      <td>give</td>\n",
       "      <td>10711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>method</td>\n",
       "      <td>1048</td>\n",
       "      <td>method</td>\n",
       "      <td>8708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>607 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            neg_word  neg_word_count         pos_word  pos_word_count\n",
       "0               data          218601             data          566608\n",
       "1            science           94229          science          177311\n",
       "2    machinelearning           93401  machinelearning          598956\n",
       "3                 ai           92834               ai          939058\n",
       "4                 ml           35018               ml          266853\n",
       "..               ...             ...              ...             ...\n",
       "602     unsupervised            1064     unsupervised           14603\n",
       "603           across            1054           across           15198\n",
       "604      opportunity            1053      opportunity           13106\n",
       "605             give            1052             give           10711\n",
       "606           method            1048           method            8708\n",
       "\n",
       "[607 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "merged_df[['neg_word_count_norm', 'pos_word_count_norm']] = scaler.fit_transform(merged_df[['neg_word_count', 'pos_word_count']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmerged_pos = merged_df.iloc[:, [2,3, 5]].sort_values(by=['pos_word_count'], ascending=False)\n",
    "unmerged_neg = merged_df.iloc[:, [0,1, 4]].sort_values(by=['neg_word_count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_pos = unmerged_pos.head(10).pos_word.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_neg = unmerged_neg.head(10).neg_word.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = list(top_10_pos)\n",
    "top_words.extend(x for x in top_10_neg if x not in top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for i in range(len(merged_df.index)):\n",
    "    if merged_df.neg_word.values[i] in top_words:\n",
    "        f.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = merged_df.iloc[f,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.grid(linestyle='--', linewidth=0.5)\n",
    "ax = sns.scatterplot(x='neg_word_count_norm',y='pos_word_count_norm',hue = 'neg_word',data = final_df,legend='full',s=50)\n",
    "ax.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.xlabel('Normalised Count in Negative Tweets')\n",
    "plt.ylabel('Normalised Count in Positive Tweets')\n",
    "plt.savefig(os.path.join(path, 'ml_word_occurrence.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg_word</th>\n",
       "      <th>neg_word_count</th>\n",
       "      <th>pos_word</th>\n",
       "      <th>pos_word_count</th>\n",
       "      <th>neg_word_count_norm</th>\n",
       "      <th>pos_word_count_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data</td>\n",
       "      <td>218601</td>\n",
       "      <td>data</td>\n",
       "      <td>566608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>science</td>\n",
       "      <td>94229</td>\n",
       "      <td>science</td>\n",
       "      <td>177311</td>\n",
       "      <td>0.428314</td>\n",
       "      <td>0.182949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>machinelearning</td>\n",
       "      <td>93401</td>\n",
       "      <td>machinelearning</td>\n",
       "      <td>598956</td>\n",
       "      <td>0.424508</td>\n",
       "      <td>0.635206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ai</td>\n",
       "      <td>92834</td>\n",
       "      <td>ai</td>\n",
       "      <td>939058</td>\n",
       "      <td>0.421902</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ml</td>\n",
       "      <td>35018</td>\n",
       "      <td>ml</td>\n",
       "      <td>266853</td>\n",
       "      <td>0.156146</td>\n",
       "      <td>0.278992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>via</td>\n",
       "      <td>34220</td>\n",
       "      <td>via</td>\n",
       "      <td>294690</td>\n",
       "      <td>0.152478</td>\n",
       "      <td>0.308850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>datascience</td>\n",
       "      <td>31478</td>\n",
       "      <td>datascience</td>\n",
       "      <td>177868</td>\n",
       "      <td>0.139874</td>\n",
       "      <td>0.183547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>amp</td>\n",
       "      <td>31426</td>\n",
       "      <td>amp</td>\n",
       "      <td>277056</td>\n",
       "      <td>0.139635</td>\n",
       "      <td>0.289936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>big</td>\n",
       "      <td>29884</td>\n",
       "      <td>big</td>\n",
       "      <td>123758</td>\n",
       "      <td>0.132547</td>\n",
       "      <td>0.125508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>python</td>\n",
       "      <td>23985</td>\n",
       "      <td>python</td>\n",
       "      <td>287146</td>\n",
       "      <td>0.105432</td>\n",
       "      <td>0.300758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>new</td>\n",
       "      <td>18470</td>\n",
       "      <td>new</td>\n",
       "      <td>249358</td>\n",
       "      <td>0.080082</td>\n",
       "      <td>0.260227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>artificial</td>\n",
       "      <td>7458</td>\n",
       "      <td>artificial</td>\n",
       "      <td>252087</td>\n",
       "      <td>0.029464</td>\n",
       "      <td>0.263154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>intelligence</td>\n",
       "      <td>6815</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>270007</td>\n",
       "      <td>0.026508</td>\n",
       "      <td>0.282375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            neg_word  neg_word_count         pos_word  pos_word_count  \\\n",
       "3               data          218601             data          566608   \n",
       "11           science           94229          science          177311   \n",
       "12   machinelearning           93401  machinelearning          598956   \n",
       "13                ai           92834               ai          939058   \n",
       "24                ml           35018               ml          266853   \n",
       "25               via           34220              via          294690   \n",
       "28       datascience           31478      datascience          177868   \n",
       "29               amp           31426              amp          277056   \n",
       "31               big           29884              big          123758   \n",
       "35            python           23985           python          287146   \n",
       "50               new           18470              new          249358   \n",
       "123       artificial            7458       artificial          252087   \n",
       "139     intelligence            6815     intelligence          270007   \n",
       "\n",
       "     neg_word_count_norm  pos_word_count_norm  \n",
       "3               1.000000             0.600510  \n",
       "11              0.428314             0.182949  \n",
       "12              0.424508             0.635206  \n",
       "13              0.421902             1.000000  \n",
       "24              0.156146             0.278992  \n",
       "25              0.152478             0.308850  \n",
       "28              0.139874             0.183547  \n",
       "29              0.139635             0.289936  \n",
       "31              0.132547             0.125508  \n",
       "35              0.105432             0.300758  \n",
       "50              0.080082             0.260227  \n",
       "123             0.029464             0.263154  \n",
       "139             0.026508             0.282375  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f339fb3a027be473131e6ac829b8dc34fc7d4e2b227bdb2c2c5f9829538e0fed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
