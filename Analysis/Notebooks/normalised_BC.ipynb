{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "path = '/Users/connormcdonald/Desktop/Masters/MIT807/Gartner Repository/Analysis/Figures'\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/connormcdonald/Desktop/Masters/MIT807/Gartner Repository/Data Collection')\n",
    "from configs import *\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mpl_toolkits.axisartist.axislines import SubplotZero\n",
    "from pylab import text\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"lualatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+mysqlconnector://'+user+':'+passwd+'@'+ip+':3306/'+schema1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/connormcdonald/Desktop/Masters/MIT807/Data/twitterMAU.csv')\n",
    "df['period']  = pd.to_datetime(df['period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.iloc[:38,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "degree = 3\n",
    "y = np.array(df1['mau'].to_list())\n",
    "X = np.array(mdates.date2num(df1['period']))\n",
    "date_index = []\n",
    "idx = 0\n",
    "for i in X:\n",
    "    date_index.append(idx)\n",
    "    idx += 1\n",
    "\n",
    "z = np.polyfit(date_index, y, degree)\n",
    "f = np.poly1d(z)\n",
    "\n",
    "df_trend = pd.DataFrame(columns=['X', 'y','d'])\n",
    "df_trend['X'] = date_index\n",
    "df_trend['y'] = y\n",
    "df_trend['d'] = X\n",
    "\n",
    "\n",
    "z = np.polyfit(df_trend.d, df_trend.y, degree)\n",
    "model = np.poly1d(z)\n",
    "results = smf.ols(formula='y ~ model(X)', data=df_trend).fit()\n",
    "\n",
    "# print(results.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mdates.date2num(df['period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fit = mdates.date2num(df['period'])\n",
    "y_fit = [model(_x) for _x in x_fit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dformat(d):\n",
    "    return d.strftime('%Y-%m')\n",
    "\n",
    "def yformat(d):\n",
    "    return d.strftime('%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_fit'] = y_fit\n",
    "df['combined_mau'] = np.where(df[\"mau\"].isnull(), df[\"y_fit\"], df[\"mau\"] )*1000000\n",
    "df['period_formatted'] = df['period'].apply(dformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = '''SELECT DATE_FORMAT(date, \\'%Y-%m\\') as date, \n",
    "COUNT(1) AS tweets,\n",
    "SUM(like_count) as likes,\n",
    "SUM(quote_count) as quotes,\n",
    "SUM(reply_count) as comments,\n",
    "SUM(retweet_count) as retweets\n",
    "FROM social.blockchain \n",
    "WHERE date < \\'2018-01-01\\'\n",
    "group by DATE_FORMAT(date, \\'%Y-%m\\') \n",
    "ORDER BY DATE_FORMAT(date, \\'%Y-%m\\') ASC'''\n",
    "df2018 = pd.read_sql(stmt, con=engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = '''SELECT DATE_FORMAT(date, \\'%Y-%m\\') as date, \n",
    "COUNT(1) AS tweets,\n",
    "SUM(like_count) as likes,\n",
    "SUM(quote_count) as quotes,\n",
    "SUM(reply_count) as comments,\n",
    "SUM(retweet_count) as retweets\n",
    "FROM social.blockchain \n",
    "WHERE date >= \\'2018-01-01\\' AND date < \\'2019-01-01\\'\n",
    "group by DATE_FORMAT(date, \\'%Y-%m\\') \n",
    "ORDER BY DATE_FORMAT(date, \\'%Y-%m\\') ASC'''\n",
    "df2019 = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = '''SELECT DATE_FORMAT(date, \\'%Y-%m\\') as date, \n",
    "COUNT(1) AS tweets,\n",
    "SUM(like_count) as likes,\n",
    "SUM(quote_count) as quotes,\n",
    "SUM(reply_count) as comments,\n",
    "SUM(retweet_count) as retweets\n",
    "FROM social.blockchain \n",
    "WHERE date >= \\'2019-01-01\\' AND date < \\'2020-06-01\\'\n",
    "group by DATE_FORMAT(date, \\'%Y-%m\\') \n",
    "ORDER BY DATE_FORMAT(date, \\'%Y-%m\\') ASC'''\n",
    "df2020 = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = '''SELECT DATE_FORMAT(date, \\'%Y-%m\\') as date, \n",
    "COUNT(1) AS tweets,\n",
    "SUM(like_count) as likes,\n",
    "SUM(quote_count) as quotes,\n",
    "SUM(reply_count) as comments,\n",
    "SUM(retweet_count) as retweets\n",
    "FROM social.blockchain \n",
    "WHERE date >= \\'2020-06-01\\'\n",
    "group by DATE_FORMAT(date, \\'%Y-%m\\') \n",
    "ORDER BY DATE_FORMAT(date, \\'%Y-%m\\') ASC'''\n",
    "df2021 = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c7/dcyx4ss130ldp4lp9ph0v16c0000gn/T/ipykernel_37993/2731392987.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2018.append(df2019, ignore_index=True)\n",
      "/var/folders/c7/dcyx4ss130ldp4lp9ph0v16c0000gn/T/ipykernel_37993/2731392987.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(df2020, ignore_index=True)\n",
      "/var/folders/c7/dcyx4ss130ldp4lp9ph0v16c0000gn/T/ipykernel_37993/2731392987.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append(df2021, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>quotes</th>\n",
       "      <th>comments</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-05</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-06</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-07</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2021-08</td>\n",
       "      <td>459401</td>\n",
       "      <td>2905291.0</td>\n",
       "      <td>356300.0</td>\n",
       "      <td>543299.0</td>\n",
       "      <td>1427199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2021-09</td>\n",
       "      <td>438051</td>\n",
       "      <td>3454590.0</td>\n",
       "      <td>325614.0</td>\n",
       "      <td>595230.0</td>\n",
       "      <td>1611273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2021-10</td>\n",
       "      <td>570588</td>\n",
       "      <td>4378248.0</td>\n",
       "      <td>407846.0</td>\n",
       "      <td>821868.0</td>\n",
       "      <td>2032221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2021-11</td>\n",
       "      <td>609901</td>\n",
       "      <td>4863002.0</td>\n",
       "      <td>353633.0</td>\n",
       "      <td>901950.0</td>\n",
       "      <td>2198923.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2021-12</td>\n",
       "      <td>578820</td>\n",
       "      <td>4918447.0</td>\n",
       "      <td>421620.0</td>\n",
       "      <td>947831.0</td>\n",
       "      <td>2340692.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  tweets      likes    quotes  comments   retweets\n",
       "0    2011-03       1        0.0       0.0       0.0        0.0\n",
       "1    2011-04       2        0.0       0.0       0.0        1.0\n",
       "2    2011-05      11        1.0       0.0       0.0        1.0\n",
       "3    2011-06      11        3.0       0.0       1.0        1.0\n",
       "4    2011-07       6        0.0       0.0       0.0        0.0\n",
       "..       ...     ...        ...       ...       ...        ...\n",
       "125  2021-08  459401  2905291.0  356300.0  543299.0  1427199.0\n",
       "126  2021-09  438051  3454590.0  325614.0  595230.0  1611273.0\n",
       "127  2021-10  570588  4378248.0  407846.0  821868.0  2032221.0\n",
       "128  2021-11  609901  4863002.0  353633.0  901950.0  2198923.0\n",
       "129  2021-12  578820  4918447.0  421620.0  947831.0  2340692.0\n",
       "\n",
       "[130 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2018.append(df2019, ignore_index=True)\n",
    "df2 = df2.append(df2020, ignore_index=True)\n",
    "df2 = df2.append(df2021, ignore_index=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df, df2, left_on='period_formatted', right_on='date', how='inner')\n",
    "\n",
    "df3['tweets_p_user'] = df3['tweets']/df3['combined_mau']\n",
    "\n",
    "df3['likes_p_user'] = df3['likes']/df3['combined_mau']\n",
    "df3['comments_p_user'] = df3['comments']/df3['combined_mau']\n",
    "df3['quotes_p_user'] = df3['quotes']/df3['combined_mau']\n",
    "df3['retweets_p_user'] = df3['retweets']/df3['combined_mau']\n",
    "\n",
    "df3['total_engagement'] = df3['likes_p_user'] + df3['comments_p_user'] + df3['quotes_p_user'] + df3['retweets_p_user']\n",
    "df3['total_engagement_og'] = df3['likes'] + df3['comments'] + df3['quotes'] + df3['retweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 0.8231709355998323\n",
      "pre: 0.9839317472242228\n",
      "post: 0.9834953136801926\n"
     ]
    }
   ],
   "source": [
    "correlation_df = df3\n",
    "correlation_df['date']  = pd.to_datetime(correlation_df['date'])\n",
    "\n",
    "correlation_pre = correlation_df[correlation_df.period_formatted < '2020-12-01']\n",
    "correlation_post = correlation_df[correlation_df.period_formatted >= '2020-12-01']\n",
    "\n",
    "\n",
    "column_1 = correlation_df[\"tweets\"]\n",
    "column_2 = correlation_df[\"total_engagement_og\"]\n",
    "correlation = column_1.corr(column_2)\n",
    "print(f\"total: {correlation}\")\n",
    "\n",
    "\n",
    "column_1 = correlation_pre[\"tweets\"]\n",
    "column_2 = correlation_pre[\"total_engagement_og\"]\n",
    "correlation = column_1.corr(column_2)\n",
    "print(f\"pre: {correlation}\")\n",
    "\n",
    "\n",
    "column_1 = correlation_post[\"tweets\"]\n",
    "column_2 = correlation_post[\"total_engagement_og\"]\n",
    "correlation = column_1.corr(column_2)\n",
    "print(f\"post: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c7/dcyx4ss130ldp4lp9ph0v16c0000gn/T/ipykernel_37993/1982449608.py:1: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "corr = []\n",
    "c = []\n",
    "p = []\n",
    "for i in range(2, len(correlation_df.index)):\n",
    "    temp_df = correlation_df.iloc[:i,:]\n",
    "    tweets = temp_df.tweets\n",
    "    engagement = temp_df.total_engagement_og\n",
    "    correlation = tweets.corr(engagement)\n",
    "    corr.append(correlation)\n",
    "    x = pearsonr(engagement, tweets)\n",
    "    c.append(x[0])\n",
    "    p.append(x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999999999999999, 0.9762210399274297, 0.9907747849205183, 0.9931541988391678, 0.9157437185514745, 0.9730441806376738, 0.9298510831080337, 0.9191849874225453, 0.9189547095731139, 0.9109495430157009, 0.9861760199469932, 0.9951342930868744, 0.9961272421871855, 0.9957077164020064, 0.9750933272931203, 0.9468170242972216, 0.9631822769798077, 0.9466386748519838, 0.9787909575513023, 0.9349696533300998, 0.9488667990926788, 0.9670626783107076, 0.9765355940523974, 0.9833925042909903, 0.949935832007426, 0.95839511176884, 0.9752872136993905, 0.9821567576987631, 0.9876322006135541, 0.9890081672466347, 0.9883024532469883, 0.9881098331837077, 0.9880060751521628, 0.9867973477021278, 0.9852987856971012, 0.9839317472242228, 0.9403841127992422, 0.9161689268271157, 0.8636090444753136]\n"
     ]
    }
   ],
   "source": [
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr plot\n",
    "line = pd.to_datetime('2014-09-01')\n",
    "line2 = pd.to_datetime('2018-03-01')\n",
    "line3 = pd.to_datetime('2020-12-01')\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Correlation')\n",
    "ax.set_ylim([0, 1])\n",
    "plt.plot(correlation_df.loc[2:].date, corr, c = 'black', linewidth = 1)\n",
    "# plt.plot(correlation_df.loc[2:].date, p, c = 'green', linewidth = 1)\n",
    "plt.axvline(x=line, c = '#E31B23', linewidth = 1, linestyle =\"--\", label= 'POI-A')\n",
    "plt.axvline(x=line3, c = '#FF9A00', linewidth = 1, linestyle =\"--\", label= 'POI-B')\n",
    "plt.axvline(x=line2, c = '#999999', linewidth = 1, linestyle =\"--\", label= 'POI-C')\n",
    "plt.legend(loc='lower left')\n",
    "plt.savefig(os.path.join(path, 'bc_correleation.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr plot\n",
    "line = pd.to_datetime('2014-09-01')\n",
    "line2 = pd.to_datetime('2018-03-01')\n",
    "line3 = pd.to_datetime('2020-12-01')\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Correlation')\n",
    "ax.set_ylim([-0.2, 0.8])\n",
    "plt.plot(correlation_df.loc[2:].date, p, c = '#339898', linewidth = 1)\n",
    "plt.axvline(x=line, c = '#E31B23', linewidth = 1, linestyle =\"--\", label= 'POI-A')\n",
    "plt.axvline(x=line3, c = '#FF9A00', linewidth = 1, linestyle =\"--\", label= 'POI-B')\n",
    "plt.axvline(x=line2, c = '#999999', linewidth = 1, linestyle =\"--\", label= 'POI-C')\n",
    "plt.legend(loc='lower left')\n",
    "plt.savefig(os.path.join(path, 'bc_pval.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 3\n",
    "y = np.array(df3['tweets_p_user'].to_list())\n",
    "X = np.array(mdates.date2num(df3['date']))\n",
    "date_index = []\n",
    "idx = 0\n",
    "for i in X:\n",
    "    date_index.append(idx)\n",
    "    idx += 1\n",
    "\n",
    "z = np.polyfit(date_index, y, degree)\n",
    "f = np.poly1d(z)\n",
    "\n",
    "df_trend = pd.DataFrame(columns=['X', 'y','d'])\n",
    "df_trend['X'] = date_index\n",
    "df_trend['y'] = y\n",
    "df_trend['d'] = X\n",
    "\n",
    "\n",
    "z = np.polyfit(df_trend.d, df_trend.y, degree)\n",
    "model = np.poly1d(z)\n",
    "results = smf.ols(formula='y ~ model(X)', data=df_trend).fit()\n",
    "\n",
    "\n",
    "X = mdates.date2num(df3['date'])\n",
    "\n",
    "x_fit = mdates.date2num(df3['date'])\n",
    "y_fit = [model(_x) for _x in x_fit]\n",
    "\n",
    "df3['y_fit_2'] = y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.550   \\\\\n",
      "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.538   \\\\\n",
      "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     46.38   \\\\\n",
      "\\textbf{Date:}             & Mon, 19 Sep 2022 & \\textbf{  Prob (F-statistic):} &  4.45e-08   \\\\\n",
      "\\textbf{Time:}             &     17:29:09     & \\textbf{  Log-Likelihood:    } &    252.34   \\\\\n",
      "\\textbf{No. Observations:} &          40      & \\textbf{  AIC:               } &    -500.7   \\\\\n",
      "\\textbf{Df Residuals:}     &          38      & \\textbf{  BIC:               } &    -497.3   \\\\\n",
      "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{Intercept} &       0.2354  &        0.034     &     6.826  &         0.000        &        0.166    &        0.305     \\\\\n",
      "\\textbf{model(X)}  &      -0.2462  &        0.036     &    -6.810  &         0.000        &       -0.319    &       -0.173     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lclc}\n",
      "\\textbf{Omnibus:}       & 25.582 & \\textbf{  Durbin-Watson:     } &    0.306  \\\\\n",
      "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   43.983  \\\\\n",
      "\\textbf{Skew:}          &  1.792 & \\textbf{  Prob(JB):          } & 2.81e-10  \\\\\n",
      "\\textbf{Kurtosis:}      &  6.680 & \\textbf{  Cond. No.          } &     966.  \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{OLS Regression Results}\n",
      "\\end{center}\n",
      "\n",
      "Notes: \\newline\n",
      " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(results.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>mau</th>\n",
       "      <th>y_fit</th>\n",
       "      <th>combined_mau</th>\n",
       "      <th>period_formatted</th>\n",
       "      <th>date</th>\n",
       "      <th>tweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>quotes</th>\n",
       "      <th>comments</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweets_p_user</th>\n",
       "      <th>likes_p_user</th>\n",
       "      <th>comments_p_user</th>\n",
       "      <th>quotes_p_user</th>\n",
       "      <th>retweets_p_user</th>\n",
       "      <th>total_engagement</th>\n",
       "      <th>y_fit_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.980447</td>\n",
       "      <td>68000000.0</td>\n",
       "      <td>2011-03</td>\n",
       "      <td>2011-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.470588e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-06-30</td>\n",
       "      <td>85.0</td>\n",
       "      <td>98.278006</td>\n",
       "      <td>85000000.0</td>\n",
       "      <td>2011-06</td>\n",
       "      <td>2011-06</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.294118e-07</td>\n",
       "      <td>3.529412e-08</td>\n",
       "      <td>1.176471e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.176471e-08</td>\n",
       "      <td>5.882353e-08</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>101.0</td>\n",
       "      <td>115.131254</td>\n",
       "      <td>101000000.0</td>\n",
       "      <td>2011-09</td>\n",
       "      <td>2011-09</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.376238e-07</td>\n",
       "      <td>9.900990e-09</td>\n",
       "      <td>9.900990e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.940594e-08</td>\n",
       "      <td>7.920792e-08</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>117.0</td>\n",
       "      <td>131.348972</td>\n",
       "      <td>117000000.0</td>\n",
       "      <td>2011-12</td>\n",
       "      <td>2011-12</td>\n",
       "      <td>65</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.555556e-07</td>\n",
       "      <td>6.837607e-08</td>\n",
       "      <td>3.418803e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.880342e-07</td>\n",
       "      <td>2.905983e-07</td>\n",
       "      <td>-0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-03-31</td>\n",
       "      <td>138.0</td>\n",
       "      <td>146.767500</td>\n",
       "      <td>138000000.0</td>\n",
       "      <td>2012-03</td>\n",
       "      <td>2012-03</td>\n",
       "      <td>78</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.652174e-07</td>\n",
       "      <td>6.521739e-08</td>\n",
       "      <td>2.173913e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.811594e-07</td>\n",
       "      <td>2.681159e-07</td>\n",
       "      <td>-0.000087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      period    mau       y_fit  combined_mau period_formatted     date  \\\n",
       "0 2011-03-31   68.0   80.980447    68000000.0          2011-03  2011-03   \n",
       "1 2011-06-30   85.0   98.278006    85000000.0          2011-06  2011-06   \n",
       "2 2011-09-30  101.0  115.131254   101000000.0          2011-09  2011-09   \n",
       "3 2011-12-31  117.0  131.348972   117000000.0          2011-12  2011-12   \n",
       "4 2012-03-31  138.0  146.767500   138000000.0          2012-03  2012-03   \n",
       "\n",
       "   tweets  likes  quotes  comments  retweets  tweets_p_user  likes_p_user  \\\n",
       "0       1    0.0     0.0       0.0       0.0   1.470588e-08  0.000000e+00   \n",
       "1      11    3.0     0.0       1.0       1.0   1.294118e-07  3.529412e-08   \n",
       "2      24    1.0     0.0       1.0       6.0   2.376238e-07  9.900990e-09   \n",
       "3      65    8.0     0.0       4.0      22.0   5.555556e-07  6.837607e-08   \n",
       "4      78    9.0     0.0       3.0      25.0   5.652174e-07  6.521739e-08   \n",
       "\n",
       "   comments_p_user  quotes_p_user  retweets_p_user  total_engagement   y_fit_2  \n",
       "0     0.000000e+00            0.0     0.000000e+00      0.000000e+00  0.000210  \n",
       "1     1.176471e-08            0.0     1.176471e-08      5.882353e-08  0.000109  \n",
       "2     9.900990e-09            0.0     5.940594e-08      7.920792e-08  0.000027  \n",
       "3     3.418803e-08            0.0     1.880342e-07      2.905983e-07 -0.000038  \n",
       "4     2.173913e-08            0.0     1.811594e-07      2.681159e-07 -0.000087  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03\n"
     ]
    }
   ],
   "source": [
    "curr_max_freq = 0\n",
    "curr_max_eng = 0\n",
    "for i in range(len(df3.index)-1):\n",
    "    a = df3.tweets_p_user[i]\n",
    "    b = df3.tweets_p_user[i+1]\n",
    "\n",
    "    c = df3.total_engagement[i]\n",
    "    d = df3.total_engagement[i+1]\n",
    "\n",
    "\n",
    "    if a > b and i !=0 and c > d and a > curr_max_freq and c > curr_max_eng and c > a:\n",
    "        print(df3.period_formatted[i])\n",
    "        curr_max_freq = df3.tweets_p_user[i]\n",
    "        curr_max_eng = df3.total_engagement[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-09\n",
      "2014-12\n",
      "2015-03\n",
      "2015-06\n",
      "2015-09\n",
      "2015-12\n",
      "2016-03\n",
      "2016-06\n",
      "2016-09\n",
      "2016-12\n",
      "2017-03\n",
      "2017-06\n",
      "2017-09\n",
      "2017-12\n",
      "2018-03\n",
      "2018-06\n",
      "2018-09\n",
      "2018-12\n",
      "2019-03\n",
      "2020-03\n",
      "2020-06\n",
      "2020-09\n",
      "2020-12\n",
      "2021-03\n",
      "2021-06\n",
      "2021-09\n",
      "2021-12\n"
     ]
    }
   ],
   "source": [
    "#when engagement overtook tweets\n",
    "\n",
    "for i in range(len(df3.index)):\n",
    "    a = df3.tweets_p_user[i]\n",
    "    b = df3.total_engagement[i]\n",
    "\n",
    "    if a < b: \n",
    "        print(df3.period_formatted[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML plot\n",
    "df3['date']  = pd.to_datetime(df3['date'])\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 3]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Monthly Tweets Per Active User')\n",
    "plt.plot(df3['date'], df3['tweets_p_user'], c = '#339898', linewidth = 1, label = 'Tweets')\n",
    "plt.plot(df3['date'], df3['y_fit_2'], c = '#E31B23', linewidth = 1, linestyle =\"--\", label= 'Polynomial Trend Line\\n ($R^2$ = 0.525)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(os.path.join(path, 'BC_normalised_tweets.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-fc1f9c3940bd>:25: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "\n",
    "#define colors to use in chart\n",
    "color_map = ['#339898', '#E31B23', '#999999', '#FF9A00']\n",
    "\n",
    "#create area chart\n",
    "plt.stackplot(df3['date'], df3['likes_p_user'], df3['comments_p_user'], df3['quotes_p_user'],df3['retweets_p_user'],\n",
    "              labels=['Likes', 'Comments', 'Quotes', 'Retweets'],\n",
    "              colors=color_map,\n",
    "              alpha=0.6)\n",
    "plt.plot(df3['date'], df3['tweets_p_user'], c = 'black', linewidth = 1,label = 'Tweets')\n",
    "\n",
    "#add legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "#add axis labels\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Monthly Metrics Per Active User')\n",
    "plt.show()\n",
    "plt.savefig(os.path.join(path, 'bc_normalised_area.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML plot\n",
    "line = pd.to_datetime('2014-09-01')\n",
    "line2 = pd.to_datetime('2018-03-01')\n",
    "line3 = pd.to_datetime('2020-12-01')\n",
    "# line4 = pd.to_datetime('2014-06-01')\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Monthly Tweets Per Active User')\n",
    "plt.plot(df3['date'], df3['tweets_p_user'], c = 'black', linewidth = 1, label = 'Tweets')\n",
    "plt.axvline(x=line, c = '#E31B23', linewidth = 1, linestyle =\"--\", label= 'PoI-A')\n",
    "plt.axvline(x=line2, c = '#999999', linewidth = 1, linestyle =\"--\", label= 'PoI-B')\n",
    "plt.axvline(x=line3, c = '#FF9A00', linewidth = 1, linestyle =\"--\", label= 'PoI-C')\n",
    "# plt.axvline(x=line4, c = '#999999', linewidth = 1, linestyle =\"--\")\n",
    "# plt.plot(df3['date'], df3['y_fit_2'], c = '#E31B23', linewidth = 1, linestyle =\"--\", label= 'Polynomial Trend Line (R^2 = 0.686)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(os.path.join(path, 'bc_shift.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/connormcdonald/Desktop/Masters/MIT807/Data/academic_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = ['2010-12-31', '2011-12-31', '2012-12-31', '2013-12-31', '2014-12-31', '2015-12-31', '2016-12-31', '2017-12-31', '2018-12-31', '2019-12-31', '2020-12-31', '2021-12-31']\n",
    "papers = [2, 0, 1, 2, 12, 41, 183, 824, 3028, 6070, 8044, 9939]\n",
    "df['papers'] = papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scopus_norm'] = df['papers']/df['scopus_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>scholar_results</th>\n",
       "      <th>scopus_results</th>\n",
       "      <th>papers</th>\n",
       "      <th>scopus_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>4510000</td>\n",
       "      <td>2478126</td>\n",
       "      <td>2</td>\n",
       "      <td>8.070615e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>4590000</td>\n",
       "      <td>2638921</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>4670000</td>\n",
       "      <td>2775816</td>\n",
       "      <td>1</td>\n",
       "      <td>3.602544e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>4360000</td>\n",
       "      <td>2901649</td>\n",
       "      <td>2</td>\n",
       "      <td>6.892632e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>4640000</td>\n",
       "      <td>2942515</td>\n",
       "      <td>12</td>\n",
       "      <td>4.078144e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>4710000</td>\n",
       "      <td>2953613</td>\n",
       "      <td>41</td>\n",
       "      <td>1.388130e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>3040000</td>\n",
       "      <td>3055033</td>\n",
       "      <td>183</td>\n",
       "      <td>5.990115e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>3450000</td>\n",
       "      <td>3151892</td>\n",
       "      <td>824</td>\n",
       "      <td>2.614303e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>3960000</td>\n",
       "      <td>3283566</td>\n",
       "      <td>3028</td>\n",
       "      <td>9.221682e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>3500000</td>\n",
       "      <td>3437602</td>\n",
       "      <td>6070</td>\n",
       "      <td>1.765766e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020</td>\n",
       "      <td>4000000</td>\n",
       "      <td>3576254</td>\n",
       "      <td>8044</td>\n",
       "      <td>2.249281e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021</td>\n",
       "      <td>6050000</td>\n",
       "      <td>3869484</td>\n",
       "      <td>9939</td>\n",
       "      <td>2.568560e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    period  scholar_results  scopus_results  papers   scopus_norm\n",
       "0     2010          4510000         2478126       2  8.070615e-07\n",
       "1     2011          4590000         2638921       0  0.000000e+00\n",
       "2     2012          4670000         2775816       1  3.602544e-07\n",
       "3     2013          4360000         2901649       2  6.892632e-07\n",
       "4     2014          4640000         2942515      12  4.078144e-06\n",
       "5     2015          4710000         2953613      41  1.388130e-05\n",
       "6     2016          3040000         3055033     183  5.990115e-05\n",
       "7     2017          3450000         3151892     824  2.614303e-04\n",
       "8     2018          3960000         3283566    3028  9.221682e-04\n",
       "9     2019          3500000         3437602    6070  1.765766e-03\n",
       "10    2020          4000000         3576254    8044  2.249281e-03\n",
       "11    2021          6050000         3869484    9939  2.568560e-03"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "degree = 3\n",
    "y = np.array(df['scopus_norm'].to_list())\n",
    "X = np.array(mdates.date2num(df['period']))\n",
    "date_index = []\n",
    "idx = 0\n",
    "for i in X:\n",
    "    date_index.append(idx)\n",
    "    idx += 1\n",
    "\n",
    "z = np.polyfit(date_index, y, degree)\n",
    "f = np.poly1d(z)\n",
    "\n",
    "df_trend = pd.DataFrame(columns=['X', 'y','d'])\n",
    "df_trend['X'] = date_index\n",
    "df_trend['y'] = y\n",
    "df_trend['d'] = X\n",
    "\n",
    "\n",
    "z = np.polyfit(df_trend.d, df_trend.y, degree)\n",
    "model = np.poly1d(z)\n",
    "results = smf.ols(formula='y ~ model(X)', data=df_trend).fit()\n",
    "\n",
    "\n",
    "X = mdates.date2num(df['period'])\n",
    "\n",
    "x_fit = mdates.date2num(df['period'])\n",
    "y_fit = [model(_x) for _x in x_fit]\n",
    "\n",
    "df['y_fit_2'] = y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.946   \\\\\n",
      "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.946   \\\\\n",
      "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &       nan   \\\\\n",
      "\\textbf{Date:}             & Sun, 18 Sep 2022 & \\textbf{  Prob (F-statistic):} &      nan    \\\\\n",
      "\\textbf{Time:}             &     08:18:18     & \\textbf{  Log-Likelihood:    } &    84.163   \\\\\n",
      "\\textbf{No. Observations:} &          12      & \\textbf{  AIC:               } &    -166.3   \\\\\n",
      "\\textbf{Df Residuals:}     &          11      & \\textbf{  BIC:               } &    -165.8   \\\\\n",
      "\\textbf{Df Model:}         &           0      & \\textbf{                     } &             \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{Intercept} &    2.085e-63  &     1.22e-64     &    17.108  &         0.000        &     1.82e-63    &     2.35e-63     \\\\\n",
      "\\textbf{model(X)}  &    1.899e-33  &     1.11e-34     &    17.108  &         0.000        &     1.65e-33    &     2.14e-33     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lclc}\n",
      "\\textbf{Omnibus:}       &  0.129 & \\textbf{  Durbin-Watson:     } &    0.762  \\\\\n",
      "\\textbf{Prob(Omnibus):} &  0.938 & \\textbf{  Jarque-Bera (JB):  } &    0.106  \\\\\n",
      "\\textbf{Skew:}          &  0.110 & \\textbf{  Prob(JB):          } &    0.949  \\\\\n",
      "\\textbf{Kurtosis:}      &  2.596 & \\textbf{  Cond. No.          } & 7.78e+29  \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{OLS Regression Results}\n",
      "\\end{center}\n",
      "\n",
      "Notes: \\newline\n",
      " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
      " [2] The condition number is large, 7.78e+29. This might indicate that there are \\newline\n",
      " strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/connormcdonald/opt/anaconda3/lib/python3.8/site-packages/scipy/stats/stats.py:1603: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=12\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    }
   ],
   "source": [
    "print(results.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML plot\n",
    "# df['period']  = pd.to_datetime(df['period'])\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 3]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Proportion of Blockchain Publications')\n",
    "plt.plot(df['period'], df['scopus_norm'], c = '#339898', linewidth = 1, label ='Publications')\n",
    "plt.plot(df['period'], df['y_fit_2'], c = '#E31B23', linewidth = 1, linestyle =\"--\", label= 'Polynomial Trend Line ($R^2$ = 0.946)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(os.path.join(path, 'BC_normalised_pubs.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9e3c927ab7d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SELECT text, YEAR(date) as year FROM social.machine_learning_only'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    519\u001b[0m         )\n\u001b[1;32m    520\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m             frame = _wrap_result(\n\u001b[0m\u001b[1;32m   1323\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m                 \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36m_wrap_result\u001b[0;34m(data, columns, index_col, coerce_float, parse_dates)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;34m\"\"\"Wrap result set of query in a DataFrame.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_date_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfrom_records\u001b[0;34m(cls, data, index, exclude, columns, coerce_float, nrows)\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0marr_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m             \u001b[0marr_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;31m# last ditch effort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;31m# last ditch effort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stmt = 'SELECT text, YEAR(date) as year FROM social.machine_learning_only'\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax = sns.violinplot(x=\"year\", y=\"char_count\", data=df, linewidth=1)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Character Count Per Tweet')\n",
    "plt.savefig(os.path.join(path, 'char_count.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Innovation Trigger\n",
    "\n",
    "stmt = '''\n",
    "SELECT A.text\n",
    "FROM social.blockchain A\n",
    "WHERE A.date >= \\'2014-08-01\\' and A.date <= \\'2014-09-30\\'\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining dictionary containing all emojis with their meanings.\n",
    "emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad', \n",
    "          ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n",
    "          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\\\': 'annoyed', \n",
    "          ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
    "          '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n",
    "          '<(-_-)>': 'robot', 'd[-_-]b': 'dj', \":'-)\": 'sadsmile', ';)': 'wink', \n",
    "          ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}\n",
    "          \n",
    "## Defining set containing all stopwords in english.\n",
    "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
    "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from', \n",
    "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're',\n",
    "             's', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
    "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those', \n",
    "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
    "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "             'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
    "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "\n",
    "# nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "def preprocess(textdata):\n",
    "    processedText = []\n",
    "    \n",
    "    # Create Lemmatizer and Stemmer.\n",
    "    wordLemm = WordNetLemmatizer()\n",
    "    \n",
    "    # Defining regex patterns.\n",
    "    urlPattern        = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "    userPattern       = '@[^\\s]+'\n",
    "    alphaPattern      = \"[^a-zA-Z0-9]\"\n",
    "    sequencePattern   = r\"(.)\\1\\1+\"\n",
    "    seqReplacePattern = r\"\\1\\1\"\n",
    "    \n",
    "    for tweet in textdata:\n",
    "        tweet = tweet.lower()\n",
    "        \n",
    "        # Replace all URls with 'URL'\n",
    "        tweet = re.sub(urlPattern,' URL',tweet)\n",
    "        # Replace all emojis.\n",
    "        for emoji in emojis.keys():\n",
    "            tweet = tweet.replace(emoji, \"EMOJI\" + emojis[emoji])        \n",
    "        # Replace @USERNAME to 'USER'.\n",
    "        tweet = re.sub(userPattern,' USER', tweet)        \n",
    "        # Replace all non alphabets.\n",
    "        tweet = re.sub(alphaPattern, \" \", tweet)\n",
    "        # Replace 3 or more consecutive letters by 2 letter.\n",
    "        tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
    "\n",
    "        tweetwords = ''\n",
    "        for word in tweet.split():\n",
    "            # Checking if the word is a stopword.\n",
    "            #if word not in stopwordlist:\n",
    "            if len(word)>1:\n",
    "                # Lemmatizing the word.\n",
    "                word = wordLemm.lemmatize(word)\n",
    "                tweetwords += (word+' ')\n",
    "            \n",
    "        processedText.append(tweetwords)\n",
    "        \n",
    "    return processedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing complete.\n",
      "Time Taken: 1 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text = df['text']\n",
    "t = time.time()\n",
    "processedtext = preprocess(text)\n",
    "print(f'Text Preprocessing complete.')\n",
    "print(f'Time Taken: {round(time.time()-t)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Total Wordcloud\n",
    "allwords = ' '.join([tweets for tweets in processedtext]) \n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('blockchain')\n",
    "# stop_words.append('ml')\n",
    "# stop_words.append('machinelearning')\n",
    "# stop_words.append('learning')\n",
    "# stop_words.append('ai')\n",
    "# stop_words.append('artificial')\n",
    "# stop_words.append('intelligence')\n",
    "# stop_words.append('artificialintelligence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 300\n",
    "# plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "wordCloud = WordCloud(\n",
    "    font_path='/Library/Fonts/cmunrm.ttf',\n",
    "    width=800, \n",
    "    height=800,\n",
    "    background_color=\"white\",\n",
    "    max_font_size = 200,\n",
    "    collocation_threshold = 50,\n",
    "    stopwords=stop_words,\n",
    "    random_state=1,\n",
    "    colormap=\"gist_heat\").generate(allwords)\n",
    "plt.imshow(wordCloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(path, 'bc_innovation_trigger.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peak\n",
    "\n",
    "stmt = '''\n",
    "SELECT A.text\n",
    "FROM social.blockchain A\n",
    "WHERE A.date >= \\'2018-02-01\\' and A.date <= \\'2018-03-31\\'\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing complete.\n",
      "Time Taken: 128 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text = df['text']\n",
    "t = time.time()\n",
    "processedtext = preprocess(text)\n",
    "print(f'Text Preprocessing complete.')\n",
    "print(f'Time Taken: {round(time.time()-t)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords = ' '.join([tweets for tweets in processedtext])\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "# plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "wordCloud = WordCloud(\n",
    "    font_path='/Library/Fonts/cmunrm.ttf',\n",
    "    width=800, \n",
    "    height=800,\n",
    "    background_color=\"white\",\n",
    "    max_font_size = 200,\n",
    "    collocation_threshold = 50,\n",
    "    stopwords=stop_words,\n",
    "    random_state=1,\n",
    "    colormap=\"gist_heat\").generate(allwords)\n",
    "plt.imshow(wordCloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(path, 'bc_peak.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trough\n",
    "\n",
    "stmt = '''\n",
    "SELECT A.text\n",
    "FROM social.blockchain A\n",
    "WHERE A.date >= \\'2019-11-01\\' and A.date <= \\'2019-12-31\\'\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['text']\n",
    "# t = time.time()\n",
    "processedtext = preprocess(text)\n",
    "# print(f'Text Preprocessing complete.')\n",
    "# print(f'Time Taken: {round(time.time()-t)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords = ' '.join([tweets for tweets in processedtext])\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "# plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "wordCloud = WordCloud(\n",
    "    font_path='/Library/Fonts/cmunrm.ttf',\n",
    "    width=800, \n",
    "    height=800,\n",
    "    background_color=\"white\",\n",
    "    max_font_size = 200,\n",
    "    collocation_threshold = 50,\n",
    "    stopwords=stop_words,\n",
    "    random_state=1,\n",
    "    colormap=\"gist_heat\").generate(allwords)\n",
    "plt.imshow(wordCloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(path, 'bc_trough.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f339fb3a027be473131e6ac829b8dc34fc7d4e2b227bdb2c2c5f9829538e0fed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
