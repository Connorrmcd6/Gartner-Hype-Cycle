{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "path = '/Users/connormcdonald/Desktop/Masters/MIT807/Gartner Repository/Analysis/Figures'\n",
    "import sys\n",
    "sys.path.insert(1, '/Users/connormcdonald/Desktop/Masters/MIT807/Gartner Repository/Data Collection')\n",
    "from configs import *\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mpl_toolkits.axisartist.axislines import SubplotZero\n",
    "from pylab import text\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"lualatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+mysqlconnector://'+user+':'+passwd+'@'+ip+':3306/'+schema1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/connormcdonald/Desktop/Masters/MIT807/Data/twitterMAU.csv')\n",
    "df['period']  = pd.to_datetime(df['period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.iloc[:38,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "degree = 3\n",
    "y = np.array(df1['mau'].to_list())\n",
    "X = np.array(mdates.date2num(df1['period']))\n",
    "date_index = []\n",
    "idx = 0\n",
    "for i in X:\n",
    "    date_index.append(idx)\n",
    "    idx += 1\n",
    "\n",
    "z = np.polyfit(date_index, y, degree)\n",
    "f = np.poly1d(z)\n",
    "\n",
    "df_trend = pd.DataFrame(columns=['X', 'y','d'])\n",
    "df_trend['X'] = date_index\n",
    "df_trend['y'] = y\n",
    "df_trend['d'] = X\n",
    "\n",
    "\n",
    "z = np.polyfit(df_trend.d, df_trend.y, degree)\n",
    "model = np.poly1d(z)\n",
    "results = smf.ols(formula='y ~ model(X)', data=df_trend).fit()\n",
    "\n",
    "# print(results.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mdates.date2num(df['period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fit = mdates.date2num(df['period'])\n",
    "y_fit = [model(_x) for _x in x_fit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dformat(d):\n",
    "    return d.strftime('%Y-%m')\n",
    "\n",
    "def yformat(d):\n",
    "    return d.strftime('%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_fit'] = y_fit\n",
    "df['combined_mau'] = np.where(df[\"mau\"].isnull(), df[\"y_fit\"], df[\"mau\"] )*1000000\n",
    "df['period_formatted'] = df['period'].apply(dformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = '''SELECT DATE_FORMAT(date, \\'%Y-%m\\') as date, \n",
    "COUNT(1) AS tweets,\n",
    "SUM(like_count) as likes,\n",
    "SUM(quote_count) as quotes,\n",
    "SUM(reply_count) as comments,\n",
    "SUM(retweet_count) as retweets\n",
    "FROM social.five_g_only \n",
    "group by DATE_FORMAT(date, \\'%Y-%m\\') \n",
    "ORDER BY DATE_FORMAT(date, \\'%Y-%m\\') ASC'''\n",
    "df2 = pd.read_sql(stmt, con=engine)\n",
    "\n",
    "df3 = pd.merge(df, df2, left_on='period_formatted', right_on='date', how='inner')\n",
    "\n",
    "df3['tweets_p_user'] = df3['tweets']/df3['combined_mau']\n",
    "\n",
    "df3['likes_p_user'] = df3['likes']/df3['combined_mau']\n",
    "df3['comments_p_user'] = df3['comments']/df3['combined_mau']\n",
    "df3['quotes_p_user'] = df3['quotes']/df3['combined_mau']\n",
    "df3['retweets_p_user'] = df3['retweets']/df3['combined_mau']\n",
    "\n",
    "df3['total_engagement'] = df3['likes_p_user'] + df3['comments_p_user'] + df3['quotes_p_user'] # removed retweets_p_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 0.9097259909114175\n",
      "pre: 0.9097259909114175\n",
      "post: nan\n"
     ]
    }
   ],
   "source": [
    "correlation_df = df3\n",
    "correlation_df['date']  = pd.to_datetime(correlation_df['date'])\n",
    "\n",
    "correlation_pre = correlation_df[correlation_df.period_formatted < '2020-03-01']\n",
    "correlation_post = correlation_df[correlation_df.period_formatted >= '2020-03-01']\n",
    "\n",
    "\n",
    "column_1 = correlation_df[\"tweets_p_user\"]\n",
    "column_2 = correlation_df[\"total_engagement\"]\n",
    "correlation = column_1.corr(column_2)\n",
    "print(f\"total: {correlation}\")\n",
    "\n",
    "\n",
    "column_1 = correlation_pre[\"tweets_p_user\"]\n",
    "column_2 = correlation_pre[\"total_engagement\"]\n",
    "correlation = column_1.corr(column_2)\n",
    "print(f\"pre: {correlation}\")\n",
    "\n",
    "\n",
    "column_1 = correlation_post[\"tweets_p_user\"]\n",
    "column_2 = correlation_post[\"total_engagement\"]\n",
    "correlation = column_1.corr(column_2)\n",
    "print(f\"post: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c7/dcyx4ss130ldp4lp9ph0v16c0000gn/T/ipykernel_1676/2356826354.py:1: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "corr = []\n",
    "c = []\n",
    "p = []\n",
    "for i in range(2, len(correlation_df.index)):\n",
    "    temp_df = correlation_df.iloc[:i,:]\n",
    "    tweets = temp_df.tweets_p_user\n",
    "    engagement = temp_df.total_engagement\n",
    "    correlation = tweets.corr(engagement)\n",
    "    corr.append(correlation)\n",
    "    x = pearsonr(engagement, tweets)\n",
    "    c.append(x[0])\n",
    "    p.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr plot\n",
    "line = pd.to_datetime('2017-06-01')\n",
    "line2 = pd.to_datetime('2018-09-01')\n",
    "# line3 = pd.to_datetime('2017-12-01')\n",
    "# line4 = pd.to_datetime('2014-06-01')\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Correlation')\n",
    "plt.plot(correlation_df.loc[2:].date, corr, c = 'black', linewidth = 1)\n",
    "plt.axvline(x=line, c = '#E31B23', linewidth = 1, linestyle =\"--\", label= 'POI-A')\n",
    "plt.axvline(x=line2, c = '#999999', linewidth = 1, linestyle =\"--\", label = \"POI-B\")\n",
    "# plt.axvline(x=line3, c = '#999999', linewidth = 1, linestyle =\"--\", label= 'POI-C')\n",
    "# plt.axvline(x=line2, c = '#FF9A00', linewidth = 1, linestyle =\"--\", label= 'POI-D')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(os.path.join(path, '5g_correleation.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 3\n",
    "y = np.array(df3['tweets_p_user'].to_list())\n",
    "X = np.array(mdates.date2num(df3['date']))\n",
    "date_index = []\n",
    "idx = 0\n",
    "for i in X:\n",
    "    date_index.append(idx)\n",
    "    idx += 1\n",
    "\n",
    "z = np.polyfit(date_index, y, degree)\n",
    "f = np.poly1d(z)\n",
    "\n",
    "df_trend = pd.DataFrame(columns=['X', 'y','d'])\n",
    "df_trend['X'] = date_index\n",
    "df_trend['y'] = y\n",
    "df_trend['d'] = X\n",
    "\n",
    "\n",
    "z = np.polyfit(df_trend.d, df_trend.y, degree)\n",
    "model = np.poly1d(z)\n",
    "results = smf.ols(formula='y ~ model(X)', data=df_trend).fit()\n",
    "\n",
    "\n",
    "X = mdates.date2num(df3['date'])\n",
    "\n",
    "x_fit = mdates.date2num(df3['date'])\n",
    "y_fit = [model(_x) for _x in x_fit]\n",
    "\n",
    "df3['y_fit_2'] = y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.698   \\\\\n",
      "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.689   \\\\\n",
      "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     78.60   \\\\\n",
      "\\textbf{Date:}             & Tue, 28 Mar 2023 & \\textbf{  Prob (F-statistic):} &  2.32e-10   \\\\\n",
      "\\textbf{Time:}             &     09:33:18     & \\textbf{  Log-Likelihood:    } &    304.86   \\\\\n",
      "\\textbf{No. Observations:} &          36      & \\textbf{  AIC:               } &    -605.7   \\\\\n",
      "\\textbf{Df Residuals:}     &          34      & \\textbf{  BIC:               } &    -602.6   \\\\\n",
      "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
      "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{Intercept} &       0.0329  &        0.004     &     8.908  &         0.000        &        0.025    &        0.040     \\\\\n",
      "\\textbf{model(X)}  &       2.1124  &        0.238     &     8.865  &         0.000        &        1.628    &        2.597     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lclc}\n",
      "\\textbf{Omnibus:}       &  3.797 & \\textbf{  Durbin-Watson:     } &    0.902  \\\\\n",
      "\\textbf{Prob(Omnibus):} &  0.150 & \\textbf{  Jarque-Bera (JB):  } &    2.215  \\\\\n",
      "\\textbf{Skew:}          &  0.373 & \\textbf{  Prob(JB):          } &    0.330  \\\\\n",
      "\\textbf{Kurtosis:}      &  2.042 & \\textbf{  Cond. No.          } & 2.73e+04  \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{OLS Regression Results}\n",
      "\\end{center}\n",
      "\n",
      "Notes: \\newline\n",
      " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
      " [2] The condition number is large, 2.73e+04. This might indicate that there are \\newline\n",
      " strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(results.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>mau</th>\n",
       "      <th>y_fit</th>\n",
       "      <th>combined_mau</th>\n",
       "      <th>period_formatted</th>\n",
       "      <th>date</th>\n",
       "      <th>tweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>quotes</th>\n",
       "      <th>comments</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweets_p_user</th>\n",
       "      <th>likes_p_user</th>\n",
       "      <th>comments_p_user</th>\n",
       "      <th>quotes_p_user</th>\n",
       "      <th>retweets_p_user</th>\n",
       "      <th>total_engagement</th>\n",
       "      <th>y_fit_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.282818</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>2010-03</td>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>3012</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.200000e-06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.200000e-06</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.106319</td>\n",
       "      <td>40000000.0</td>\n",
       "      <td>2010-06</td>\n",
       "      <td>2010-06-01</td>\n",
       "      <td>4502</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1578.0</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>8.500000e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>8.500000e-07</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-09-30</td>\n",
       "      <td>49.0</td>\n",
       "      <td>44.504028</td>\n",
       "      <td>49000000.0</td>\n",
       "      <td>2010-09</td>\n",
       "      <td>2010-09-01</td>\n",
       "      <td>3170</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>6.326531e-07</td>\n",
       "      <td>4.081633e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>6.734694e-07</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>54.0</td>\n",
       "      <td>63.256920</td>\n",
       "      <td>54000000.0</td>\n",
       "      <td>2010-12</td>\n",
       "      <td>2010-12-01</td>\n",
       "      <td>4814</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2991.0</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>1.592593e-06</td>\n",
       "      <td>1.851852e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>1.611111e-06</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.980447</td>\n",
       "      <td>68000000.0</td>\n",
       "      <td>2011-03</td>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>8282</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12041.0</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>1.250000e-06</td>\n",
       "      <td>2.941176e-08</td>\n",
       "      <td>1.470588e-08</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>1.294118e-06</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      period   mau      y_fit  combined_mau period_formatted       date  \\\n",
       "0 2010-03-31  30.0   5.282818    30000000.0          2010-03 2010-03-01   \n",
       "1 2010-06-30  40.0  25.106319    40000000.0          2010-06 2010-06-01   \n",
       "2 2010-09-30  49.0  44.504028    49000000.0          2010-09 2010-09-01   \n",
       "3 2010-12-31  54.0  63.256920    54000000.0          2010-12 2010-12-01   \n",
       "4 2011-03-31  68.0  80.980447    68000000.0          2011-03 2011-03-01   \n",
       "\n",
       "   tweets  likes  quotes  comments  retweets  tweets_p_user  likes_p_user  \\\n",
       "0    3012   36.0     0.0       0.0     253.0       0.000100  1.200000e-06   \n",
       "1    4502   34.0     0.0       0.0    1578.0       0.000113  8.500000e-07   \n",
       "2    3170   31.0     0.0       2.0     888.0       0.000065  6.326531e-07   \n",
       "3    4814   86.0     0.0       1.0    2991.0       0.000089  1.592593e-06   \n",
       "4    8282   85.0     1.0       2.0   12041.0       0.000122  1.250000e-06   \n",
       "\n",
       "   comments_p_user  quotes_p_user  retweets_p_user  total_engagement   y_fit_2  \n",
       "0     0.000000e+00   0.000000e+00         0.000008      1.200000e-06  0.000098  \n",
       "1     0.000000e+00   0.000000e+00         0.000039      8.500000e-07  0.000095  \n",
       "2     4.081633e-08   0.000000e+00         0.000018      6.734694e-07  0.000093  \n",
       "3     1.851852e-08   0.000000e+00         0.000055      1.611111e-06  0.000091  \n",
       "4     2.941176e-08   1.470588e-08         0.000177      1.294118e-06  0.000089  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06\n",
      "2018-09\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "curr_max_freq = 0\n",
    "curr_max_eng = 0\n",
    "for i in range(len(df3.index)-1):\n",
    "    a = df3.tweets_p_user[i]\n",
    "    b = df3.tweets_p_user[i+1]\n",
    "\n",
    "    c = df3.total_engagement[i]\n",
    "    d = df3.total_engagement[i+1]\n",
    "\n",
    "\n",
    "    if a > b and i !=0 and c > d and a > curr_max_freq and c > curr_max_eng and c > a:\n",
    "        print(df3.period_formatted[i])\n",
    "        curr_max_freq = df3.tweets_p_user[i]\n",
    "        curr_max_eng = df3.total_engagement[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06\n",
      "2017-09\n",
      "2017-12\n",
      "2018-03\n",
      "2018-06\n",
      "2018-09\n",
      "2018-12\n"
     ]
    }
   ],
   "source": [
    "#when engagement overtook tweets\n",
    "\n",
    "for i in range(len(df3.index)):\n",
    "    a = df3.tweets_p_user[i]\n",
    "    b = df3.total_engagement[i]\n",
    "\n",
    "    if a < b: \n",
    "        print(df3.period_formatted[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML plot\n",
    "df3['date']  = pd.to_datetime(df3['date'])\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [6,6]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Monthly Tweets Per Active User')\n",
    "plt.plot(df3['date'], df3['tweets_p_user'], c = '#339898', linewidth = 1, label = 'Tweets')\n",
    "plt.plot(df3['date'], df3['y_fit_2'], c = '#E31B23', linewidth = 1, linestyle =\"--\", label= 'Polynomial Trend Line ($R^2$ = 0.698)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(os.path.join(path, '5g_normalised_tweets.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [6,6]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "\n",
    "#define colors to use in chart\n",
    "color_map = ['#339898', '#E31B23', '#999999', '#FF9A00']\n",
    "\n",
    "#create area chart\n",
    "plt.stackplot(df3['date'], df3['likes_p_user'], df3['comments_p_user'], df3['quotes_p_user'],df3['retweets_p_user'],\n",
    "              labels=['Likes', 'Comments', 'Quotes', 'Retweets'],\n",
    "              colors=color_map,\n",
    "              alpha=0.6)\n",
    "plt.plot(df3['date'], df3['tweets_p_user'], c = 'black', linewidth = 1,label = 'Tweets')\n",
    "\n",
    "#add legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "#add axis labels\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Monthly Metrics Per Active User')\n",
    "plt.savefig(os.path.join(path, '5g_normalised_area.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-f7b055bcb435>:25: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "\n",
    "#define colors to use in chart\n",
    "color_map = ['#339898', '#E31B23', '#999999']\n",
    "\n",
    "#create area chart\n",
    "plt.stackplot(df3['date'], df3['likes_p_user'], df3['comments_p_user'], df3['quotes_p_user'],\n",
    "              labels=['Likes', 'Comments', 'Quotes'],\n",
    "              colors=color_map,\n",
    "              alpha=0.6)\n",
    "plt.plot(df3['date'], df3['tweets_p_user'], c = 'black', linewidth = 1,label = 'Tweets')\n",
    "\n",
    "#add legend\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "#add axis labels\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Monthly Metrics Per Active User')\n",
    "plt.show()\n",
    "plt.savefig(os.path.join(path, '5g_normalised_area2.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5g plot\n",
    "line = pd.to_datetime('2017-06-01')\n",
    "line2 = pd.to_datetime('2018-09-01')\n",
    "# line3 = pd.to_datetime('2014-06-01')\n",
    "# line4 = pd.to_datetime('2015-03-01')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [6,6]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Monthly Tweets Per Active User')\n",
    "plt.plot(df3['date'], df3['tweets_p_user'], c = 'black', linewidth = 1, label = 'Tweets')\n",
    "plt.axvline(x=line, c = '#E31B23', linewidth = 1, linestyle =\"--\", label= 'POI-A')\n",
    "plt.axvline(x=line2, c = '#999999', linewidth = 1, linestyle =\"--\", label = \"POI-B\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(os.path.join(path, '5g_shift.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/connormcdonald/Desktop/Masters/MIT807/Data/academic_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = ['2010-12-31', '2011-12-31', '2012-12-31', '2013-12-31', '2014-12-31', '2015-12-31', '2016-12-31', '2017-12-31', '2018-12-31', '2019-12-31', '2020-12-31', '2021-12-31']\n",
    "papers = [585, 881, 921, 874, 1365, 2024, 3225, 4740, 6857, 9050, 9579, 12018]\n",
    "df['papers'] = papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scopus_norm'] = df['papers']/df['scopus_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>scholar_results</th>\n",
       "      <th>scopus_results</th>\n",
       "      <th>papers</th>\n",
       "      <th>scopus_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>4510000</td>\n",
       "      <td>2478126</td>\n",
       "      <td>585</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>4590000</td>\n",
       "      <td>2638921</td>\n",
       "      <td>881</td>\n",
       "      <td>0.000334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>4670000</td>\n",
       "      <td>2775816</td>\n",
       "      <td>921</td>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>4360000</td>\n",
       "      <td>2901649</td>\n",
       "      <td>874</td>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>4640000</td>\n",
       "      <td>2942515</td>\n",
       "      <td>1365</td>\n",
       "      <td>0.000464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>4710000</td>\n",
       "      <td>2953613</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.000685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>3040000</td>\n",
       "      <td>3055033</td>\n",
       "      <td>3225</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>3450000</td>\n",
       "      <td>3151892</td>\n",
       "      <td>4740</td>\n",
       "      <td>0.001504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>3960000</td>\n",
       "      <td>3283566</td>\n",
       "      <td>6857</td>\n",
       "      <td>0.002088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>3500000</td>\n",
       "      <td>3437602</td>\n",
       "      <td>9050</td>\n",
       "      <td>0.002633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020</td>\n",
       "      <td>4000000</td>\n",
       "      <td>3576254</td>\n",
       "      <td>9579</td>\n",
       "      <td>0.002679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021</td>\n",
       "      <td>6050000</td>\n",
       "      <td>3869484</td>\n",
       "      <td>12018</td>\n",
       "      <td>0.003106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    period  scholar_results  scopus_results  papers  scopus_norm\n",
       "0     2010          4510000         2478126     585     0.000236\n",
       "1     2011          4590000         2638921     881     0.000334\n",
       "2     2012          4670000         2775816     921     0.000332\n",
       "3     2013          4360000         2901649     874     0.000301\n",
       "4     2014          4640000         2942515    1365     0.000464\n",
       "5     2015          4710000         2953613    2024     0.000685\n",
       "6     2016          3040000         3055033    3225     0.001056\n",
       "7     2017          3450000         3151892    4740     0.001504\n",
       "8     2018          3960000         3283566    6857     0.002088\n",
       "9     2019          3500000         3437602    9050     0.002633\n",
       "10    2020          4000000         3576254    9579     0.002679\n",
       "11    2021          6050000         3869484   12018     0.003106"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "degree = 3\n",
    "y = np.array(df['scopus_norm'].to_list())\n",
    "X = np.array(mdates.date2num(df['period']))\n",
    "date_index = []\n",
    "idx = 0\n",
    "for i in X:\n",
    "    date_index.append(idx)\n",
    "    idx += 1\n",
    "\n",
    "z = np.polyfit(date_index, y, degree)\n",
    "f = np.poly1d(z)\n",
    "\n",
    "df_trend = pd.DataFrame(columns=['X', 'y','d'])\n",
    "df_trend['X'] = date_index\n",
    "df_trend['y'] = y\n",
    "df_trend['d'] = X\n",
    "\n",
    "\n",
    "z = np.polyfit(df_trend.d, df_trend.y, degree)\n",
    "model = np.poly1d(z)\n",
    "results = smf.ols(formula='y ~ model(X)', data=df_trend).fit()\n",
    "\n",
    "\n",
    "X = mdates.date2num(df['period'])\n",
    "\n",
    "x_fit = mdates.date2num(df['period'])\n",
    "y_fit = [model(_x) for _x in x_fit]\n",
    "\n",
    "df['y_fit_2'] = y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.829   \\\\\n",
      "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.829   \\\\\n",
      "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &       nan   \\\\\n",
      "\\textbf{Date:}             & Tue, 28 Mar 2023 & \\textbf{  Prob (F-statistic):} &      nan    \\\\\n",
      "\\textbf{Time:}             &     08:25:27     & \\textbf{  Log-Likelihood:    } &    76.113   \\\\\n",
      "\\textbf{No. Observations:} &          12      & \\textbf{  AIC:               } &    -150.2   \\\\\n",
      "\\textbf{Df Residuals:}     &          11      & \\textbf{  BIC:               } &    -149.7   \\\\\n",
      "\\textbf{Df Model:}         &           0      & \\textbf{                     } &             \\\\\n",
      "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{Intercept} &    6.185e-64  &     4.99e-65     &    12.393  &         0.000        &     5.09e-64    &     7.28e-64     \\\\\n",
      "\\textbf{model(X)}  &   -1.231e-33  &     9.93e-35     &   -12.393  &         0.000        &    -1.45e-33    &    -1.01e-33     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lclc}\n",
      "\\textbf{Omnibus:}       & 12.321 & \\textbf{  Durbin-Watson:     } &    0.390  \\\\\n",
      "\\textbf{Prob(Omnibus):} &  0.002 & \\textbf{  Jarque-Bera (JB):  } &    7.011  \\\\\n",
      "\\textbf{Skew:}          & -1.595 & \\textbf{  Prob(JB):          } &   0.0300  \\\\\n",
      "\\textbf{Kurtosis:}      &  4.960 & \\textbf{  Cond. No.          } & 1.70e+30  \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{OLS Regression Results}\n",
      "\\end{center}\n",
      "\n",
      "Notes: \\newline\n",
      " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
      " [2] The condition number is large, 1.7e+30. This might indicate that there are \\newline\n",
      " strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/connormcdonald/opt/anaconda3/lib/python3.8/site-packages/scipy/stats/_stats_py.py:1772: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=12\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    }
   ],
   "source": [
    "print(results.summary().as_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML plot\n",
    "# df['period']  = pd.to_datetime(df['period'])\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.rcParams[\"figure.figsize\"] = [6,6]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Proportion of 5G Publications')\n",
    "plt.plot(df['period'], df['scopus_norm'], c = '#339898', linewidth = 1, label ='Publications')\n",
    "plt.plot(df['period'], df['y_fit_2'], c = '#E31B23', linewidth = 1, linestyle =\"--\", label= 'Polynomial Trend Line ($R^2$ = 0.829)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(os.path.join(path, '5g_normalised_pubs.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m stmt \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mSELECT CHAR_LENGTH (text) as char_count, YEAR(date) as year FROM social.five_g_only\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_sql(stmt, con\u001b[39m=\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py:590\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39mread_table(\n\u001b[1;32m    582\u001b[0m         sql,\n\u001b[1;32m    583\u001b[0m         index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    587\u001b[0m         chunksize\u001b[39m=\u001b[39mchunksize,\n\u001b[1;32m    588\u001b[0m     )\n\u001b[1;32m    589\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 590\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[1;32m    591\u001b[0m         sql,\n\u001b[1;32m    592\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m    593\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    594\u001b[0m         coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[1;32m    595\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m    596\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    597\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py:1560\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype)\u001b[0m\n\u001b[1;32m   1512\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m \u001b[39mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \n\u001b[1;32m   1557\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m args \u001b[39m=\u001b[39m _convert_params(sql, params)\n\u001b[0;32m-> 1560\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   1561\u001b[0m columns \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mkeys()\n\u001b[1;32m   1563\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py:1405\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1403\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexecute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1404\u001b[0m     \u001b[39m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1405\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnectable\u001b[39m.\u001b[39;49mexecution_options()\u001b[39m.\u001b[39;49mexecute(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py:402\u001b[0m, in \u001b[0;36m_decorate_with_warning.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_warning:\n\u001b[1;32m    401\u001b[0m     _warn_with_version(message, version, wtype, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m--> 402\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py:3176\u001b[0m, in \u001b[0;36mEngine.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   3158\u001b[0m \u001b[39m\"\"\"Executes the given construct and returns a\u001b[39;00m\n\u001b[1;32m   3159\u001b[0m \u001b[39m:class:`_engine.CursorResult`.\u001b[39;00m\n\u001b[1;32m   3160\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3173\u001b[0m \n\u001b[1;32m   3174\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3175\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnect(close_with_result\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 3176\u001b[0m \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49mexecute(statement, \u001b[39m*\u001b[39;49mmultiparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1291\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(statement, util\u001b[39m.\u001b[39mstring_types):\n\u001b[1;32m   1283\u001b[0m     util\u001b[39m.\u001b[39mwarn_deprecated_20(\n\u001b[1;32m   1284\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing a string to Connection.execute() is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1285\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdeprecated and will be removed in version 2.0.  Use the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdriver-level SQL string.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1289\u001b[0m     )\n\u001b[0;32m-> 1291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_driver_sql(\n\u001b[1;32m   1292\u001b[0m         statement,\n\u001b[1;32m   1293\u001b[0m         multiparams,\n\u001b[1;32m   1294\u001b[0m         params,\n\u001b[1;32m   1295\u001b[0m         _EMPTY_EXECUTION_OPTS,\n\u001b[1;32m   1296\u001b[0m         future\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1297\u001b[0m     )\n\u001b[1;32m   1299\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1300\u001b[0m     meth \u001b[39m=\u001b[39m statement\u001b[39m.\u001b[39m_execute_on_connection\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1595\u001b[0m, in \u001b[0;36mConnection._exec_driver_sql\u001b[0;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[1;32m   1585\u001b[0m         (\n\u001b[1;32m   1586\u001b[0m             statement,\n\u001b[1;32m   1587\u001b[0m             distilled_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1591\u001b[0m             statement, distilled_parameters, execution_options\n\u001b[1;32m   1592\u001b[0m         )\n\u001b[1;32m   1594\u001b[0m dialect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\n\u001b[0;32m-> 1595\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[1;32m   1596\u001b[0m     dialect,\n\u001b[1;32m   1597\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_statement,\n\u001b[1;32m   1598\u001b[0m     statement,\n\u001b[1;32m   1599\u001b[0m     distilled_parameters,\n\u001b[1;32m   1600\u001b[0m     execution_options,\n\u001b[1;32m   1601\u001b[0m     statement,\n\u001b[1;32m   1602\u001b[0m     distilled_parameters,\n\u001b[1;32m   1603\u001b[0m )\n\u001b[1;32m   1605\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m future:\n\u001b[1;32m   1606\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1862\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1859\u001b[0m             branched\u001b[39m.\u001b[39mclose()\n\u001b[1;32m   1861\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1862\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[1;32m   1863\u001b[0m         e, statement, parameters, cursor, context\n\u001b[1;32m   1864\u001b[0m     )\n\u001b[1;32m   1866\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py:2047\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2043\u001b[0m         util\u001b[39m.\u001b[39mraise_(\n\u001b[1;32m   2044\u001b[0m             sqlalchemy_exception, with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m], from_\u001b[39m=\u001b[39me\n\u001b[1;32m   2045\u001b[0m         )\n\u001b[1;32m   2046\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2047\u001b[0m         util\u001b[39m.\u001b[39;49mraise_(exc_info[\u001b[39m1\u001b[39;49m], with_traceback\u001b[39m=\u001b[39;49mexc_info[\u001b[39m2\u001b[39;49m])\n\u001b[1;32m   2049\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reentrant_error\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/util/compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    205\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[1;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[1;32m    209\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1818\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1819\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1820\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1821\u001b[0m         )\n\u001b[1;32m   1823\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[1;32m   1824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1825\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1826\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1830\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[1;32m   1831\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 732\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/mysql/connector/cursor.py:568\u001b[0m, in \u001b[0;36mMySQLCursor.execute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute_iter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39mcmd_query_iter(stmt))\n\u001b[1;32m    567\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 568\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_result(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mcmd_query(stmt))\n\u001b[1;32m    569\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInterfaceError:\n\u001b[1;32m    570\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39m_have_next_result:  \u001b[39m# pylint: disable=W0212\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/mysql/connector/cursor.py:480\u001b[0m, in \u001b[0;36mMySQLCursor._handle_result\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_description \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    479\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39munread_result \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_resultset()\n\u001b[1;32m    481\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39maffected_rows\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m result:\n\u001b[1;32m    482\u001b[0m     \u001b[39m# Weak test, must be an OK-packet\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39munread_result \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/mysql/connector/cursor.py:983\u001b[0m, in \u001b[0;36mMySQLCursorBuffered._handle_resultset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_handle_resultset\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 983\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rows, eof) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mget_rows()\n\u001b[1;32m    984\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rowcount \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rows)\n\u001b[1;32m    985\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_eof(eof)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/mysql/connector/connection.py:712\u001b[0m, in \u001b[0;36mMySQLConnection.get_rows\u001b[0;34m(self, count, binary, columns, raw, prep_stmt)\u001b[0m\n\u001b[1;32m    709\u001b[0m         rows \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_protocol\u001b[39m.\u001b[39mread_binary_result(\n\u001b[1;32m    710\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_socket, columns, count, charset)\n\u001b[1;32m    711\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 712\u001b[0m         rows \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_protocol\u001b[39m.\u001b[39;49mread_text_result(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_socket,\n\u001b[1;32m    713\u001b[0m                                                \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_server_version,\n\u001b[1;32m    714\u001b[0m                                                count\u001b[39m=\u001b[39;49mcount)\n\u001b[1;32m    715\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    716\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munread_result \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/mysql/connector/protocol.py:366\u001b[0m, in \u001b[0;36mMySQLProtocol.read_text_result\u001b[0;34m(self, sock, version, count)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39mif\u001b[39;00m eof \u001b[39mor\u001b[39;00m i \u001b[39m==\u001b[39m count:\n\u001b[1;32m    365\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m packet \u001b[39m=\u001b[39m sock\u001b[39m.\u001b[39;49mrecv()\n\u001b[1;32m    367\u001b[0m \u001b[39mif\u001b[39;00m packet\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\xff\u001b[39;00m\u001b[39m\\xff\u001b[39;00m\u001b[39m\\xff\u001b[39;00m\u001b[39m'\u001b[39m):\n\u001b[1;32m    368\u001b[0m     datas \u001b[39m=\u001b[39m [packet[\u001b[39m4\u001b[39m:]]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/mysql/connector/network.py:246\u001b[0m, in \u001b[0;36mBaseMySQLSocket.recv_plain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m packet_len \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    245\u001b[0m \u001b[39mwhile\u001b[39;00m packet_len \u001b[39m<\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[0;32m--> 246\u001b[0m     chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msock\u001b[39m.\u001b[39;49mrecv(\u001b[39m4\u001b[39;49m \u001b[39m-\u001b[39;49m packet_len)\n\u001b[1;32m    247\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunk:\n\u001b[1;32m    248\u001b[0m         \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mInterfaceError(errno\u001b[39m=\u001b[39m\u001b[39m2013\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1223\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1224\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1225\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(buflen)\n\u001b[1;32m   1227\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m)\n\u001b[1;32m   1102\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m x:\n\u001b[1;32m   1103\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m SSL_ERROR_EOF \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stmt = 'SELECT CHAR_LENGTH (text) as char_count, YEAR(date) as year FROM social.five_g_only'\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax = sns.violinplot(x=\"year\", y=\"char_count\", data=df, linewidth=1)\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Character Count Per Tweet')\n",
    "plt.savefig(os.path.join(path, '5g_char_count.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Innovation Trigger\n",
    "\n",
    "stmt = '''\n",
    "SELECT A.text\n",
    "FROM social.five_g_only A\n",
    "WHERE A.date >= \\'2017-05-01\\' and A.date <= \\'2017-06-30\\'\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining dictionary containing all emojis with their meanings.\n",
    "emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad', \n",
    "          ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n",
    "          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\\\': 'annoyed', \n",
    "          ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
    "          '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n",
    "          '<(-_-)>': 'robot', 'd[-_-]b': 'dj', \":'-)\": 'sadsmile', ';)': 'wink', \n",
    "          ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}\n",
    "          \n",
    "## Defining set containing all stopwords in english.\n",
    "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
    "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from', \n",
    "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're',\n",
    "             's', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
    "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those', \n",
    "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
    "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "             'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
    "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "\n",
    "# nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "def preprocess(textdata):\n",
    "    processedText = []\n",
    "    \n",
    "    # Create Lemmatizer and Stemmer.\n",
    "    wordLemm = WordNetLemmatizer()\n",
    "    \n",
    "    # Defining regex patterns.\n",
    "    urlPattern        = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "    userPattern       = '@[^\\s]+'\n",
    "    alphaPattern      = \"[^a-zA-Z0-9]\"\n",
    "    sequencePattern   = r\"(.)\\1\\1+\"\n",
    "    seqReplacePattern = r\"\\1\\1\"\n",
    "    \n",
    "    for tweet in textdata:\n",
    "        tweet = tweet.lower()\n",
    "        \n",
    "        # Replace all URls with 'URL'\n",
    "        tweet = re.sub(urlPattern,' URL',tweet)\n",
    "        # Replace all emojis.\n",
    "        for emoji in emojis.keys():\n",
    "            tweet = tweet.replace(emoji, \"EMOJI\" + emojis[emoji])        \n",
    "        # Replace @USERNAME to 'USER'.\n",
    "        tweet = re.sub(userPattern,' USER', tweet)        \n",
    "        # Replace all non alphabets.\n",
    "        tweet = re.sub(alphaPattern, \" \", tweet)\n",
    "        # Replace 3 or more consecutive letters by 2 letter.\n",
    "        tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
    "\n",
    "        tweetwords = ''\n",
    "        for word in tweet.split():\n",
    "            # Checking if the word is a stopword.\n",
    "            #if word not in stopwordlist:\n",
    "            if len(word)>1:\n",
    "                # Lemmatizing the word.\n",
    "                word = wordLemm.lemmatize(word)\n",
    "                tweetwords += (word+' ')\n",
    "            \n",
    "        processedText.append(tweetwords)\n",
    "        \n",
    "    return processedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing complete.\n",
      "Time Taken: 8 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text = df['text']\n",
    "t = time.time()\n",
    "processedtext = preprocess(text)\n",
    "print(f'Text Preprocessing complete.')\n",
    "print(f'Time Taken: {round(time.time()-t)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Total Wordcloud\n",
    "allwords = ' '.join([tweets for tweets in processedtext]) \n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('5g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 300\n",
    "# plt.rcParams[\"figure.figsize\"] = [8, 4]\n",
    "wordCloud = WordCloud(\n",
    "    font_path='/Library/Fonts/cmunrm.ttf',\n",
    "    width=800, \n",
    "    height=800,\n",
    "    background_color=\"white\",\n",
    "    max_font_size = 200,\n",
    "    min_font_size = 15,\n",
    "    collocation_threshold = 50,\n",
    "    stopwords=stop_words,\n",
    "    random_state=1,\n",
    "    colormap=\"gist_heat\").generate(allwords)\n",
    "plt.imshow(wordCloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(path, '5g_innovation_trigger.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first peak\n",
    "\n",
    "stmt = '''\n",
    "SELECT A.text\n",
    "FROM social.five_g_only A\n",
    "WHERE A.date >= \\'2018-08-01\\' and A.date <= \\'2018-09-30\\'\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(stmt, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing complete.\n",
      "Time Taken: 16 seconds\n"
     ]
    }
   ],
   "source": [
    "text = df['text']\n",
    "t = time.time()\n",
    "processedtext = preprocess(text)\n",
    "print(f'Text Preprocessing complete.')\n",
    "print(f'Time Taken: {round(time.time()-t)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords = ' '.join([tweets for tweets in processedtext])\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "wordCloud = WordCloud(\n",
    "    font_path='/Library/Fonts/cmunrm.ttf',\n",
    "    width=800, \n",
    "    height=800,\n",
    "    background_color=\"white\",\n",
    "    max_font_size = 200,\n",
    "    min_font_size = 15,\n",
    "    collocation_threshold = 50,\n",
    "    stopwords=stop_words,\n",
    "    random_state=1,\n",
    "    colormap=\"gist_heat\").generate(allwords)\n",
    "plt.imshow(wordCloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig(os.path.join(path, '5g_peak_1.pdf'), format='pdf',bbox_inches='tight',pad_inches = 0)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f339fb3a027be473131e6ac829b8dc34fc7d4e2b227bdb2c2c5f9829538e0fed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
